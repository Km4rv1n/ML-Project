{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision-Tree Classifier**"
      ],
      "metadata": {
        "id": "JiAEQHBIkUxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "717btS84aSSG",
        "outputId": "f97a39da-24f3-4fac-b619-7723cef50fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0 0]\n",
            " [1 1 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.92      0.88      0.87         8\n",
            "weighted avg       0.92      0.88      0.87         8\n",
            "\n",
            "Depth of the tree: 3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your training and test data\n",
        "train_data_path = \"/content/training_Helicobacter pylori.data\"\n",
        "test_data_path = \"/content/test_Helicobacter pylori.data\"\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None, delimiter=',')\n",
        "test_data = pd.read_csv(test_data_path, header=None, delimiter=',')\n",
        "\n",
        "# Assuming the last column is the target variable for both train and test datasets\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Encode the target variable\n",
        "labelencoder = LabelEncoder()\n",
        "y_train_encoded = labelencoder.fit_transform(y_train)\n",
        "y_test_encoded = labelencoder.transform(y_test)  # Transform the test labels with the same encoder\n",
        "\n",
        "# Initialize the DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_predicted = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test_encoded, y_predicted))\n",
        "print(classification_report(y_test_encoded, y_predicted))\n",
        "\n",
        "# Print the depth of the tree\n",
        "print(\"Depth of the tree:\", classifier.get_depth())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KNN*\n",
        "label encoded output\n"
      ],
      "metadata": {
        "id": "-y_DPE6EkiM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your training and test data\n",
        "train_data_path = \"/content/training_Helicobacter pylori.data\"\n",
        "test_data_path = \"/content/test_Helicobacter pylori.data\"\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None, delimiter=',')\n",
        "test_data = pd.read_csv(test_data_path, header=None, delimiter=',')\n",
        "\n",
        "# Assuming the last column is the target variable for both train and test datasets\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Encode the target variable\n",
        "labelencoder = LabelEncoder()\n",
        "y_train_encoded = labelencoder.fit_transform(y_train)\n",
        "y_test_encoded = labelencoder.transform(y_test)  # Transform the test labels with the same encoder\n",
        "\n",
        "# Initialize the KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=10)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_predicted = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test_encoded, y_predicted))\n",
        "print(classification_report(y_test_encoded, y_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAQIfkIphAN6",
        "outputId": "0a4adf0e-4245-411c-9ee8-204ac10f1580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0 0]\n",
            " [0 2 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KNN*\n",
        "non-encoded output"
      ],
      "metadata": {
        "id": "S5Nt6RSNkwXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your training and test data\n",
        "train_data_path = \"/content/training_Helicobacter pylori.data\"\n",
        "test_data_path = \"/content/test_Helicobacter pylori.data\"\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None, delimiter=',')\n",
        "test_data = pd.read_csv(test_data_path, header=None, delimiter=',')\n",
        "\n",
        "# Assuming the last column is the target variable for both train and test datasets\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "\n",
        "# Initialize the KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=2)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_predicted = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_predicted))\n",
        "print(classification_report(y_test, y_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf9DsNmhh4QH",
        "outputId": "e08f47b7-e77a-4a38-d7e5-0ab420a9c6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0 0]\n",
            " [0 2 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Genotype-1       1.00      1.00      1.00         2\n",
            "  Genotype-2       1.00      1.00      1.00         2\n",
            " Genotype-M1       1.00      1.00      1.00         2\n",
            " Genotype-M2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reason why we get such a perfect results: samll test set"
      ],
      "metadata": {
        "id": "WWqeEPWgj7QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**"
      ],
      "metadata": {
        "id": "WFLLzsGFnmt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your training and test data\n",
        "train_data_path = \"/content/training_Helicobacter pylori.data\"  # Update this path\n",
        "test_data_path = \"/content/test_Helicobacter pylori.data\"  # Update this path\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None, delimiter=',')\n",
        "test_data = pd.read_csv(test_data_path, header=None, delimiter=',')\n",
        "\n",
        "# Assuming the last column is the target variable for both train and test datasets\n",
        "X_train = train_data.iloc[:, :-1]  # Features from training data\n",
        "y_train = train_data.iloc[:, -1]   # Target variable from training data\n",
        "X_test = test_data.iloc[:, :-1]    # Features from test data\n",
        "y_test = test_data.iloc[:, -1]     # Target variable from test data\n",
        "\n",
        "# Initialize the LogisticRegression\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_predicted = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_predicted))\n",
        "print(classification_report(y_test, y_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUtSAAxTlB8J",
        "outputId": "1c3c4e00-edab-4cf1-cc87-4b7ed8205a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0 0]\n",
            " [1 1 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Genotype-1       0.67      1.00      0.80         2\n",
            "  Genotype-2       1.00      0.50      0.67         2\n",
            " Genotype-M1       1.00      1.00      1.00         2\n",
            " Genotype-M2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.92      0.88      0.87         8\n",
            "weighted avg       0.92      0.88      0.87         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is performing well overall with an accuracy of 88%, but there are specific issues with Genotype-2, where half of the samples were misclassified. This could suggest that features distinguishing Genotype-2 might be similar to those of Genotype-1 or not distinct enough for the model to differentiate consistently."
      ],
      "metadata": {
        "id": "dGJlgxWEmPEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gaussian Naive Bayes classifier**"
      ],
      "metadata": {
        "id": "laEmekjcnyn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your training and test data\n",
        "train_data_path = \"/content/training_Helicobacter pylori.data\"  # Update this path\n",
        "test_data_path = \"/content/test_Helicobacter pylori.data\"  # Update this path\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None, delimiter=',')\n",
        "test_data = pd.read_csv(test_data_path, header=None, delimiter=',')\n",
        "\n",
        "# Assuming the last column is the target variable for both train and test datasets\n",
        "X_train = train_data.iloc[:, :-1]  # Features from training data\n",
        "y_train = train_data.iloc[:, -1]   # Target variable from training data\n",
        "X_test = test_data.iloc[:, :-1]    # Features from test data\n",
        "y_test = test_data.iloc[:, -1]     # Target variable from test data\n",
        "\n",
        "# Since GaussianNB typically handles numeric features well and assuming your data is already numeric\n",
        "# If your data included categorical data, you would need to encode it or use one-hot encoding\n",
        "\n",
        "# Initialize the GaussianNB\n",
        "classifier = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_predicted = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_predicted))\n",
        "print(classification_report(y_test, y_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAzSCMOkmQXW",
        "outputId": "e8385dd4-8928-48c0-85ac-499c539ca5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0 0]\n",
            " [1 1 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Genotype-1       0.67      1.00      0.80         2\n",
            "  Genotype-2       1.00      0.50      0.67         2\n",
            " Genotype-M1       1.00      1.00      1.00         2\n",
            " Genotype-M2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.92      0.88      0.87         8\n",
            "weighted avg       0.92      0.88      0.87         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Machine**"
      ],
      "metadata": {
        "id": "NH25PfoWn_tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your training and test data\n",
        "train_data_path = \"/content/training_Helicobacter pylori.data\"  # Update this path\n",
        "test_data_path = \"/content/test_Helicobacter pylori.data\"  # Update this path\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None, delimiter=',')\n",
        "test_data = pd.read_csv(test_data_path, header=None, delimiter=',')\n",
        "\n",
        "# Assuming the last column is the target variable for both train and test datasets\n",
        "X_train = train_data.iloc[:, :-1]  # Features from training data\n",
        "y_train = train_data.iloc[:, -1]   # Target variable from training data\n",
        "X_test = test_data.iloc[:, :-1]    # Features from test data\n",
        "y_test = test_data.iloc[:, -1]     # Target variable from test data\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "classifier = svm.SVC(kernel='poly')  # Using polynomial kernel\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_predicted = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_predicted))\n",
        "print(classification_report(y_test, y_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L03V81EYoH0F",
        "outputId": "69bd4a8b-0360-4455-b506-de2ae7744ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0 0]\n",
            " [1 1 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Genotype-1       0.67      1.00      0.80         2\n",
            "  Genotype-2       1.00      0.50      0.67         2\n",
            " Genotype-M1       1.00      1.00      1.00         2\n",
            " Genotype-M2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.92      0.88      0.87         8\n",
            "weighted avg       0.92      0.88      0.87         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1],\n",
        "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(svm.SVC(), parameters, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
        "\n",
        "# Evaluate with the best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "y_predicted = best_model.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_predicted))\n",
        "print(classification_report(y_test, y_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s34ECr0vokQz",
        "outputId": "023908bb-edd3-4d08-f9d5-1fa54f58fa10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "Best cross-validation score: 1.00\n",
            "[[2 0 0 0]\n",
            " [1 1 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Genotype-1       0.67      1.00      0.80         2\n",
            "  Genotype-2       1.00      0.50      0.67         2\n",
            " Genotype-M1       1.00      1.00      1.00         2\n",
            " Genotype-M2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.92      0.88      0.87         8\n",
            "weighted avg       0.92      0.88      0.87         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi Layered Perceptron (MLP)**"
      ],
      "metadata": {
        "id": "YLSLrVESoz2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0Oz9jrZ8UJIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##ORIGINAL DATASET\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv('training_Helicobacter pylori.data', header=None)\n",
        "test_df = pd.read_csv('test_Helicobacter pylori.data', header=None)\n",
        "\n",
        "# Separate features and target labels\n",
        "X_train = train_df.iloc[:, :-1].values  # Features (nucleotide sequences)\n",
        "y_train = train_df.iloc[:, -1].values   # Target labels (genotype)\n",
        "\n",
        "X_test = test_df.iloc[:, :-1].values    # Features (nucleotide sequences)\n",
        "y_test = test_df.iloc[:, -1].values     # Target labels (genotype)\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "y_test_categorical = to_categorical(y_test_encoded)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(200, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(201, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "adam_optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_categorical, epochs=500, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate total squared error loss\n",
        "total_squared_error = np.sum((y_test_categorical - y_pred)**2)\n",
        "print(\"Total Squared Error Loss:\", total_squared_error)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "mpnPEI7uUQSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#COMBINED DATASET\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('combined_Helicobacter_pylori_data.csv', header=None)\n",
        "\n",
        "# Separate features and target labels\n",
        "X = data.iloc[:, :-1].values  # Features (nucleotide sequences)\n",
        "y = data.iloc[:, -1].values   # Target labels (genotype)\n",
        "\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(200, activation='tanh', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(201, activation='tanh'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "#learning_rate = 0.001\n",
        "#adam_optimizer = Adam(lr=learning_rate)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "RQNSKKsXUb0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recurrent Neural Networks (RNNs)**\n"
      ],
      "metadata": {
        "id": "XRdlbE7FuLzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Embedding\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "oTFW160FuLM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data_path = \"/content/training_Helicobacter pylori.data\"\n",
        "test_data_path = \"/content/test_Helicobacter pylori.data\"\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None, delimiter=',')\n",
        "test_data = pd.read_csv(test_data_path, header=None, delimiter=',')\n",
        "\n",
        "# Split features and target\n",
        "X_train = train_data.iloc[:, :-1].values\n",
        "y_train = train_data.iloc[:, -1].values\n",
        "X_test = test_data.iloc[:, :-1].values\n",
        "y_test = test_data.iloc[:, -1].values\n",
        "\n",
        "# Encode categorical target variable\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "# Optionally, scale the features if needed\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#Reshape input to be [samples, time steps, features]\n",
        "X_train_scaled = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n"
      ],
      "metadata": {
        "id": "TXSbFgvAueMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    SimpleRNN(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    SimpleRNN(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(len(np.unique(y_train_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SDnD1UqvGIj",
        "outputId": "c5594b97-118e-4e16-f6e6-873727abdb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 1, 50)             12550     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 50)             0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17804 (69.55 KB)\n",
            "Trainable params: 17804 (69.55 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train_encoded, epochs=100, batch_size=18, validation_data=(X_test_scaled, y_test_encoded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0IbskJ6vJi7",
        "outputId": "0af898a0-3389-4539-cdcc-9125e968c9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 8s 186ms/step - loss: 1.4223 - accuracy: 0.3651 - val_loss: 1.1364 - val_accuracy: 0.6250\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6744 - accuracy: 0.8254 - val_loss: 0.8998 - val_accuracy: 0.6250\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3067 - accuracy: 0.9841 - val_loss: 0.8249 - val_accuracy: 0.6250\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.1743 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.6250\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.1072 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.6250\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.6250\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.6250\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.6250\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.8329 - val_accuracy: 0.6250\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.8401 - val_accuracy: 0.6250\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.8460 - val_accuracy: 0.6250\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.8509 - val_accuracy: 0.6250\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.8553 - val_accuracy: 0.6250\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.6250\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.8635 - val_accuracy: 0.6250\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.8672 - val_accuracy: 0.6250\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.8706 - val_accuracy: 0.6250\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.6250\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.8757 - val_accuracy: 0.6250\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.6250\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.8793 - val_accuracy: 0.6250\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.6250\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.6250\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8822 - val_accuracy: 0.6250\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.6250\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8855 - val_accuracy: 0.6250\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.8878 - val_accuracy: 0.6250\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8901 - val_accuracy: 0.6250\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.6250\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.8937 - val_accuracy: 0.6250\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.6250\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.6250\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.6250\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8980 - val_accuracy: 0.6250\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8995 - val_accuracy: 0.6250\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.6250\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.9015 - val_accuracy: 0.6250\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9023 - val_accuracy: 0.6250\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9033 - val_accuracy: 0.6250\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.6250\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.6250\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9062 - val_accuracy: 0.6250\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.6250\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.6250\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9086 - val_accuracy: 0.6250\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9092 - val_accuracy: 0.6250\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9098 - val_accuracy: 0.6250\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9101 - val_accuracy: 0.6250\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9104 - val_accuracy: 0.6250\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9114 - val_accuracy: 0.6250\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9121 - val_accuracy: 0.6250\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.6250\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9136 - val_accuracy: 0.6250\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9146 - val_accuracy: 0.6250\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9157 - val_accuracy: 0.6250\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9172 - val_accuracy: 0.6250\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9185 - val_accuracy: 0.6250\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.6250\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9208 - val_accuracy: 0.6250\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9218 - val_accuracy: 0.6250\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9227 - val_accuracy: 0.6250\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9236 - val_accuracy: 0.6250\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.6250\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.6250\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.6250\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.6250\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.6250\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9276 - val_accuracy: 0.6250\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9280 - val_accuracy: 0.6250\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.6250\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9291 - val_accuracy: 0.6250\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.6250\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9297 - val_accuracy: 0.6250\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9299 - val_accuracy: 0.6250\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.6250\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9305 - val_accuracy: 0.6250\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.6250\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.6250\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 0.6250\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.6250\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.6250\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9365 - val_accuracy: 0.6250\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.6250\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.6250\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.6250\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9409 - val_accuracy: 0.6250\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.6250\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.6250\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9437 - val_accuracy: 0.6250\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9442 - val_accuracy: 0.6250\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9445 - val_accuracy: 0.6250\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.6250\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9451 - val_accuracy: 0.6250\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.6250\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.6250\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.6250\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.6250\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.6250\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9483 - val_accuracy: 0.6250\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9488 - val_accuracy: 0.6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hgNHPoevNDF",
        "outputId": "82da4931-24c9-45da-b77c-16abe8011fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step - loss: 0.9488 - accuracy: 0.6250\n",
            "Test Accuracy: 0.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "predictions = model.predict(X_test_scaled)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_encoded, predicted_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAHMCgeavOiI",
        "outputId": "dffacf10-978c-4f47-f560-d2fce299b0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 323ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.50      1.00      0.67         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.62         8\n",
            "   macro avg       0.62      0.62      0.58         8\n",
            "weighted avg       0.62      0.62      0.58         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reasons for Poor Results:\n",
        "- Insufficient Training Data: RNNs and other deep learning models generally require large amounts of data to perform well. If the dataset is too small, the model may not be able to learn effectively.\n",
        "- Inappropriate Model Complexity: If the model is too complex relative to the amount of data available, it may overfit the training data, failing to generalize well to unseen data.\n",
        "- Suboptimal Hyperparameters:\n",
        " - Number of Layers and Neurons: Too many or too few neurons or layers can lead to underfitting or overfitting.\n",
        " - Learning Rate: If set too high or too low, it can lead to poor convergence.\n",
        "- Feature Representation: The way features are encoded and prepared might not be optimal for capturing the relationships necessary for classification.\n",
        "- Sequence Length: In RNNs, the length of the input sequences can significantly impact performance. Incorrect sequence processing might hinder learning."
      ],
      "metadata": {
        "id": "ZcVrJuzfwsMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recurrent Neural Networks (RNNs) with 70/30 split **\n"
      ],
      "metadata": {
        "id": "bCCj2EXXj3VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Embedding\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_V28RNt8kIpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data_path=\"/content/combined_Helicobacter_pylori.data\"\n",
        "\n",
        "data = pd.read_csv(data_path, header=None, delimiter=',')\n",
        "\n",
        "# Split features and target\n",
        "X = data.iloc[:, :-1].values  # Features (nucleotide sequences)\n",
        "y = data.iloc[:, -1].values   # Target labels (genotype)\n",
        "\n",
        "# Split the Dataset into Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70)\n",
        "\n",
        "# Encode categorical target variable\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "# Optionally, scale the features if needed\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#Reshape input to be [samples, time steps, features]\n",
        "X_train_scaled = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n"
      ],
      "metadata": {
        "id": "P16rIntwkNMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    SimpleRNN(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    SimpleRNN(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(len(np.unique(y_train_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4yLZGhUkOZh",
        "outputId": "ae055d61-d7f7-42c8-e139-7805d1527b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 1, 50)             12550     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 50)             0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17804 (69.55 KB)\n",
            "Trainable params: 17804 (69.55 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train_encoded, epochs=100, batch_size=18, validation_data=(X_test_scaled, y_test_encoded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm4MrQxUkVkH",
        "outputId": "b892c1b1-aa4a-463f-9d1a-c1ad4906ab69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 4s 393ms/step - loss: 1.9857 - accuracy: 0.1020 - val_loss: 1.3355 - val_accuracy: 0.4545\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.1437 - accuracy: 0.5306 - val_loss: 0.8109 - val_accuracy: 0.8636\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.6632 - accuracy: 0.8367 - val_loss: 0.5414 - val_accuracy: 0.9091\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4066 - accuracy: 0.8980 - val_loss: 0.3899 - val_accuracy: 0.9091\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2586 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9545\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2221 - accuracy: 0.9796 - val_loss: 0.2400 - val_accuracy: 0.9545\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1596 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9545\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9545\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9545\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1126 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9545\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9545\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9545\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9545\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9545\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9545\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9545\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9545\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9545\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9545\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9545\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9545\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9545\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9545\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9545\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9545\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9545\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9545\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9545\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9545\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9545\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9545\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9545\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9545\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9545\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9545\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9545\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9545\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9545\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9545\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9545\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9545\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9545\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9545\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9545\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9545\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9545\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9545\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9545\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9545\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9545\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9545\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9545\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9545\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9545\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9545\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9545\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9545\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9545\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9545\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9545\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9545\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9545\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9545\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9545\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9545\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9545\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9545\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9545\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9545\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9545\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9545\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9545\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9545\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9545\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9545\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9545\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9545\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9545\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9545\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9545\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9545\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9545\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9545\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9545\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9545\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9545\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9545\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9545\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9545\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9545\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9545\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9545\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9545\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9545\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9545\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9545\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9545\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9545\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9545\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzzRmw_nkZBj",
        "outputId": "b38db993-99d5-470d-915f-6939bc42db07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1250 - accuracy: 0.9545\n",
            "Test Accuracy: 0.9545454382896423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "predictions = model.predict(X_test_scaled)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_encoded, predicted_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxOWaERYkbmm",
        "outputId": "74d1c9d0-c034-44a4-fd7b-a91b77d29059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 272ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92         6\n",
            "           1       1.00      0.67      0.80         3\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.96      0.92      0.93        22\n",
            "weighted avg       0.96      0.95      0.95        22\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recurrent Neural Networks (RNNs) with 80/20 split **\n"
      ],
      "metadata": {
        "id": "NOvG9tZhmgoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Embedding\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bbUNu69wmjPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data_path=\"/content/combined_Helicobacter_pylori.data\"\n",
        "\n",
        "data = pd.read_csv(data_path, header=None, delimiter=',')\n",
        "\n",
        "# Split features and target\n",
        "X = data.iloc[:, :-1].values  # Features (nucleotide sequences)\n",
        "y = data.iloc[:, -1].values   # Target labels (genotype)\n",
        "\n",
        "# Split the Dataset into Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80)\n",
        "\n",
        "# Encode categorical target variable\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "# Optionally, scale the features if needed\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#Reshape input to be [samples, time steps, features]\n",
        "X_train_scaled = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n"
      ],
      "metadata": {
        "id": "3XTZ0BPZmnNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    SimpleRNN(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    SimpleRNN(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(len(np.unique(y_train_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AHoIkgYmyhZ",
        "outputId": "2f024a45-1e71-427e-fea0-b31a329853bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, 1, 50)             12550     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 50)             0         \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17804 (69.55 KB)\n",
            "Trainable params: 17804 (69.55 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train_encoded, epochs=100, batch_size=18, validation_data=(X_test_scaled, y_test_encoded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rn1U4LQm1OD",
        "outputId": "eaebac1f-52a3-4cb3-ad71-a8b46e2308ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 3s 252ms/step - loss: 1.4174 - accuracy: 0.3750 - val_loss: 0.7376 - val_accuracy: 0.8667\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.6027 - accuracy: 0.8929 - val_loss: 0.3663 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4027 - accuracy: 0.9464 - val_loss: 0.2121 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.1352 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfUbO2N2m4Kp",
        "outputId": "16bafd9d-dec8-4b2b-a2da-027978b51f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "predictions = model.predict(X_test_scaled)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_encoded, predicted_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19GhGJz_m6Tc",
        "outputId": "e928655a-0155-48e5-8972-54b39842c49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 286ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         3\n",
            "           3       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset analysis**"
      ],
      "metadata": {
        "id": "tVrd0t5nxLgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each entry 201 attributes, the last one class attribute.\n",
        "\n",
        "Training dataset:\n",
        " -Genotype-M1: 16 entitites\n",
        " -Genotype-M2: 16 entities\n",
        " -Genotype-1: 16 entries\n",
        " -Genotype-2: 16 entries\n",
        "\n",
        "So, the training dataset is balanced(each class is equally represented).\n",
        "\n",
        "Testing dataset:\n",
        " -Genotype-M1: 2 entitites\n",
        " -Genotype-M2: 2 entities\n",
        " -Genotype-1: 2 entries\n",
        " -Genotype-2: 2 entries\n",
        "\n",
        "So, the testing dataset is balanced(each class is equally represented)."
      ],
      "metadata": {
        "id": "SDR_bpNRxRlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Here I am trying to use one hot encoding and Hamming Distance instead**"
      ],
      "metadata": {
        "id": "_l61b1oj0UvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load your training and test data\n",
        "train_data_path = \"/content/training_Helicobacter pylori.data\"\n",
        "test_data_path = \"/content/test_Helicobacter pylori.data\"\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None, delimiter=',')\n",
        "test_data = pd.read_csv(test_data_path, header=None, delimiter=',')\n",
        "\n",
        "# Assuming the last column is the target variable for both train and test datasets\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# One-hot encode categorical features\n",
        "encoder = OneHotEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_test_encoded = encoder.fit_transform(X_test)\n",
        "\n",
        "\n",
        "# Initialize the KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5, metric='hamming')\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_predicted = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_predicted))\n",
        "print(classification_report(y_test, y_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8XBpsFq1EIw",
        "outputId": "f7907688-fe21-4651-bc10-d642db0e65dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0 0 0]\n",
            " [0 2 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Genotype-1       1.00      1.00      1.00         2\n",
            "  Genotype-2       1.00      1.00      1.00         2\n",
            " Genotype-M1       1.00      1.00      1.00         2\n",
            " Genotype-M2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA**"
      ],
      "metadata": {
        "id": "elM6Wdrgjwc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your dataset\n",
        "data_path = \"/content/combined_Helicobacter_pylori.data\"\n",
        "data = pd.read_csv(data_path, header=None)\n",
        "target = data.iloc[:, -1]\n",
        "data = data.iloc[:, :-1]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_standardized = scaler.fit_transform(data)\n",
        "print(\"Data before PCA:\", data_standardized.shape)\n",
        "print(\"Example of 2 samples:\", data_standardized[:2, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwDTSWit3N4v",
        "outputId": "31036192-1135-4f71-f9d4-d54a954eb618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data before PCA: (71, 200)\n",
            "Example of 2 samples: [[-1.01418511  0.          1.00363943  0.33071891 -1.01418511  1.01418511\n",
            "  -0.97716212 -1.01418511  1.01418511  1.00342902  0.          0.27524094\n",
            "   0.95860259  0.          0.95860259  1.00801634  0.          1.01418511\n",
            "   1.01418511  0.          0.62622429 -1.01418511 -1.01418511  0.67976924\n",
            "  -1.01418511 -1.01418511  1.01418511 -0.74151419  0.62578077  0.97558795\n",
            "  -0.90582163 -0.54660817 -0.94408124 -1.16598311 -0.47343208  0.7145896\n",
            "  -0.45173702  0.56936942  0.97984693  0.28578809 -0.62622429 -0.66129346\n",
            "  -0.61751353  1.01418511 -0.40643715 -0.54543245  0.08518586 -0.52537874\n",
            "  -0.73724678 -0.36320016 -1.05901685 -0.85539892 -0.64273516 -0.49993801\n",
            "   0.55384878  0.90527968  0.90527968  1.07794671 -0.51536118  0.53913101\n",
            "   0.71992099  0.98353922  0.92986961  0.49127649 -0.23207321 -0.46094751\n",
            "  -0.63857273 -0.53766246  1.31036972  0.09050495 -0.35791143 -0.95860259\n",
            "   0.1501669  -0.03388911 -0.3984314  -0.81121278 -0.01144815  2.19845664\n",
            "   0.27915411 -0.46604027  0.71391887  1.50745379  0.4421896   0.53881317\n",
            "  -0.29700719  0.111671   -0.57030896 -0.67088106 -0.30664405  0.78762819\n",
            "   0.54606379 -0.80695825 -0.42829958 -1.03293868 -0.84542935 -1.0723429\n",
            "  -0.14263724  0.90064118  0.77826111 -0.80394335  0.9693646   0.02543723\n",
            "   0.69931193  0.42466504  0.7013888  -0.43739841 -0.33196648  0.88564121\n",
            "  -0.3598145  -0.2743644   1.01102514 -0.50759133  0.9151452  -0.63381499\n",
            "  -0.88034084 -0.51942482 -0.22121338 -0.14179276  1.00474559 -0.54271931\n",
            "   0.72042765  0.4097136  -0.34219305  0.07097661 -0.45848488 -0.40908156\n",
            "  -0.43177253 -0.84558909  1.48512778  0.58277152 -0.56110103 -0.53357399\n",
            "   0.61287242  1.55929275 -0.57076669 -0.3036247   0.98230837 -0.7478084\n",
            "  -0.42502344 -0.69863079  0.72022261  0.32828924 -0.66747903  0.8811266\n",
            "  -0.99086807  0.44034836 -1.18334274 -0.06744037 -0.58592922 -0.61067846\n",
            "   1.66233852  1.36013418  0.98885223  0.92690523 -0.47864716 -0.69476468\n",
            "  -1.15184237 -0.3433722   1.00931684 -0.53605394  0.69144039 -0.48776228\n",
            "  -0.38602846  0.09517721 -0.62080884 -0.57210461  0.51731991  0.70518321\n",
            "  -0.39951785 -0.39737875  0.18256155 -0.02649142 -0.05371346  0.4760166\n",
            "  -0.62984851 -0.50736557  0.5817578   0.53003765  0.54913299  1.005366\n",
            "  -0.74956214  1.64591743 -0.94084217 -0.65230207 -0.24917682 -0.44741249\n",
            "  -0.17025131 -0.60447052  0.59978859  0.15276001 -0.17025131 -0.60097413\n",
            "   0.37255425  0.37255425 -0.40972659 -0.65896303 -0.3431443   1.09798813\n",
            "  -0.59621763  0.59849903]\n",
            " [-1.01418511  0.          1.00363943  0.33071891 -1.01418511  1.01418511\n",
            "  -0.97716212 -1.01418511  1.01418511  1.00342902  0.          0.27524094\n",
            "   0.95860259  0.          0.95860259  1.00801634  0.          1.01418511\n",
            "   1.01418511  0.          0.62622429 -1.01418511 -1.01418511  0.67976924\n",
            "  -1.01418511 -1.01418511  1.01418511 -0.74151419  0.62578077  0.97558795\n",
            "  -0.90582163 -0.54660817 -0.94408124 -1.16598311 -0.47343208  0.7145896\n",
            "  -0.45173702  0.56936942  0.97984693  0.28578809 -0.62622429 -0.66129346\n",
            "  -0.61751353  1.01418511 -0.40643715 -0.54543245  0.08518586 -0.52537874\n",
            "  -0.73724678 -0.36320016 -1.05901685 -0.85539892 -0.64273516 -0.49993801\n",
            "   0.55384878  0.90527968  0.90527968  1.07794671 -0.51536118  0.53913101\n",
            "   0.71992099  0.98353922  0.92986961  0.49127649 -0.23207321 -0.46094751\n",
            "  -0.63857273 -0.53766246  1.31036972  0.09050495 -0.35791143 -0.95860259\n",
            "   0.1501669  -0.03388911 -0.3984314  -0.81121278 -0.01144815  2.19845664\n",
            "   0.27915411 -0.46604027  0.71391887  1.50745379  0.4421896   0.53881317\n",
            "  -0.29700719  0.111671   -0.57030896 -0.67088106 -0.30664405  0.78762819\n",
            "   0.54606379 -0.80695825 -0.42829958 -1.03293868 -0.84542935 -1.0723429\n",
            "  -0.14263724  0.90064118  0.77826111 -0.80394335  0.9693646   0.02543723\n",
            "   0.69931193  0.42466504  0.7013888  -0.43739841 -0.33196648  0.88564121\n",
            "  -0.3598145  -0.2743644   1.01102514 -0.50759133  0.9151452  -0.63381499\n",
            "  -0.88034084 -0.51942482 -0.22121338 -0.14179276  1.00474559 -0.54271931\n",
            "   0.72042765  0.4097136  -0.34219305  0.07097661 -0.94434198 -0.40908156\n",
            "  -0.43177253 -0.84558909  1.48512778  0.58277152 -0.56110103 -0.53357399\n",
            "   0.61287242  1.55929275 -0.57076669 -0.3036247   0.98230837 -0.7478084\n",
            "  -0.42502344 -0.69863079  0.72022261  0.32828924 -0.66747903  0.8811266\n",
            "  -0.99086807  0.44034836 -1.18334274 -0.06744037 -0.58592922 -0.61067846\n",
            "   1.66233852  1.36013418  0.98885223  0.92690523 -0.47864716 -0.69476468\n",
            "  -1.15184237 -0.3433722   1.00931684 -0.53605394  0.69144039 -0.48776228\n",
            "  -0.38602846  0.09517721 -0.62080884 -0.57210461  0.51731991  0.70518321\n",
            "  -0.39951785 -0.39737875  0.18256155 -0.02649142 -0.05371346  0.4760166\n",
            "  -0.62984851 -0.50736557  0.5817578   0.53003765  0.54913299  1.005366\n",
            "  -0.74956214  1.64591743 -0.94084217 -0.65230207 -0.24917682 -0.44741249\n",
            "  -0.17025131 -0.60447052  0.59978859  0.15276001 -0.17025131 -0.60097413\n",
            "   0.37255425  0.37255425 -0.40972659 -0.65896303 -0.3431443   1.09798813\n",
            "  -0.59621763  0.59849903]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the covariance matrix\n",
        "covariance_matrix = np.cov(data_standardized, rowvar=False)\n",
        "print(\"Covariance Matrix:\", covariance_matrix)\n",
        "\n",
        "# Calculate eigenvectors and eigenvalues\n",
        "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
        "print(\"eigenvalues Matrix:\", eigenvalues)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0ipHi6H4DXI",
        "outputId": "9a203640-77cb-4ecf-9059-28032d4e556b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covariance Matrix: [[ 1.01428571  0.         -1.00373899 ... -0.20247681  0.59627677\n",
            "  -0.59855841]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-1.00373899  0.          1.01428571 ...  0.18882222 -0.54723365\n",
            "   0.63509059]\n",
            " ...\n",
            " [-0.20247681  0.          0.18882222 ...  1.01428571 -0.52301464\n",
            "  -0.28367687]\n",
            " [ 0.59627677  0.         -0.54723365 ... -0.52301464  1.01428571\n",
            "   0.31052254]\n",
            " [-0.59855841  0.          0.63509059 ... -0.28367687  0.31052254\n",
            "   1.01428571]]\n",
            "eigenvalues Matrix: [ 6.86667892e+01+0.00000000e+00j  3.81053619e+01+0.00000000e+00j\n",
            "  2.63429359e+01+0.00000000e+00j  1.39487748e+01+0.00000000e+00j\n",
            "  1.23141385e+01+0.00000000e+00j  8.63888806e+00+0.00000000e+00j\n",
            "  5.59365663e+00+0.00000000e+00j  4.66437734e+00+0.00000000e+00j\n",
            "  2.87013707e+00+0.00000000e+00j  2.49802849e+00+0.00000000e+00j\n",
            "  1.38687608e+00+0.00000000e+00j  1.17913793e+00+0.00000000e+00j\n",
            "  1.00405490e+00+0.00000000e+00j  9.97952250e-01+0.00000000e+00j\n",
            "  9.21267330e-01+0.00000000e+00j  8.39260448e-01+0.00000000e+00j\n",
            "  8.13468245e-01+0.00000000e+00j  7.26335534e-01+0.00000000e+00j\n",
            "  6.97098634e-01+0.00000000e+00j  6.44404881e-01+0.00000000e+00j\n",
            "  5.90684964e-01+0.00000000e+00j  5.88270437e-01+0.00000000e+00j\n",
            "  5.12135624e-01+0.00000000e+00j  4.49107285e-01+0.00000000e+00j\n",
            "  2.86231729e-01+0.00000000e+00j  4.00995799e-01+0.00000000e+00j\n",
            "  3.46140460e-01+0.00000000e+00j  3.67990581e-01+0.00000000e+00j\n",
            "  2.48727938e-01+0.00000000e+00j  2.39063220e-01+0.00000000e+00j\n",
            "  2.21849143e-01+0.00000000e+00j  1.76571046e-01+0.00000000e+00j\n",
            "  1.73316419e-01+0.00000000e+00j  1.35173990e-01+0.00000000e+00j\n",
            "  1.50632856e-01+0.00000000e+00j  1.47927007e-01+0.00000000e+00j\n",
            "  1.20676946e-01+0.00000000e+00j  1.12533209e-01+0.00000000e+00j\n",
            "  8.85330356e-02+0.00000000e+00j  7.95237347e-02+0.00000000e+00j\n",
            "  6.47343997e-02+0.00000000e+00j  6.12432364e-02+0.00000000e+00j\n",
            "  5.84509046e-02+0.00000000e+00j  5.42920369e-02+0.00000000e+00j\n",
            "  4.34902857e-02+0.00000000e+00j  3.86471377e-02+0.00000000e+00j\n",
            "  3.38606411e-02+0.00000000e+00j  3.04201213e-02+0.00000000e+00j\n",
            "  2.44783547e-02+0.00000000e+00j  1.98973687e-02+0.00000000e+00j\n",
            "  1.89294233e-02+0.00000000e+00j  1.37297837e-02+0.00000000e+00j\n",
            "  1.28862846e-02+0.00000000e+00j  9.08932309e-03+0.00000000e+00j\n",
            "  8.08516617e-03+0.00000000e+00j  5.72601158e-03+0.00000000e+00j\n",
            "  4.24020392e-03+0.00000000e+00j  3.70836595e-03+0.00000000e+00j\n",
            "  3.21260722e-03+0.00000000e+00j  1.19241765e-03+0.00000000e+00j\n",
            "  6.56395167e-04+0.00000000e+00j -1.51989645e-14+0.00000000e+00j\n",
            "  1.09543133e-14+0.00000000e+00j -8.87716925e-15+0.00000000e+00j\n",
            "  7.49212931e-15+0.00000000e+00j -7.00803526e-15+0.00000000e+00j\n",
            "  7.11186512e-15+0.00000000e+00j  6.87757883e-15+0.00000000e+00j\n",
            " -6.25061262e-15+3.77229503e-16j -6.25061262e-15-3.77229503e-16j\n",
            " -6.24409192e-15+0.00000000e+00j -5.57040139e-15+1.20288781e-16j\n",
            " -5.57040139e-15-1.20288781e-16j  5.93488101e-15+0.00000000e+00j\n",
            "  5.58433818e-15+0.00000000e+00j  5.37989268e-15+2.63481043e-16j\n",
            "  5.37989268e-15-2.63481043e-16j -5.04158765e-15+6.20396074e-16j\n",
            " -5.04158765e-15-6.20396074e-16j -5.22042908e-15+0.00000000e+00j\n",
            "  5.00966395e-15+0.00000000e+00j  4.71324158e-15+8.99453127e-17j\n",
            "  4.71324158e-15-8.99453127e-17j  4.29972607e-15+3.23512254e-16j\n",
            "  4.29972607e-15-3.23512254e-16j  4.38015796e-15+0.00000000e+00j\n",
            " -4.74013171e-15+9.28594652e-17j -4.74013171e-15-9.28594652e-17j\n",
            " -4.52530738e-15+2.52797648e-16j -4.52530738e-15-2.52797648e-16j\n",
            " -4.21015541e-15+0.00000000e+00j -4.07937775e-15+0.00000000e+00j\n",
            " -3.73390509e-15+7.55311597e-16j -3.73390509e-15-7.55311597e-16j\n",
            " -3.64194661e-15+2.94232425e-16j -3.64194661e-15-2.94232425e-16j\n",
            " -3.38779206e-15+3.51692477e-16j -3.38779206e-15-3.51692477e-16j\n",
            " -3.44955137e-15+0.00000000e+00j  3.74934297e-15+1.85014422e-16j\n",
            "  3.74934297e-15-1.85014422e-16j  3.76910779e-15+0.00000000e+00j\n",
            "  3.55329225e-15+4.35761179e-16j  3.55329225e-15-4.35761179e-16j\n",
            "  3.47018546e-15+1.17896797e-16j  3.47018546e-15-1.17896797e-16j\n",
            "  3.32669252e-15+0.00000000e+00j  3.01954751e-15+0.00000000e+00j\n",
            "  2.94956941e-15+0.00000000e+00j -2.90938343e-15+3.13696771e-16j\n",
            " -2.90938343e-15-3.13696771e-16j -3.03263003e-15+0.00000000e+00j\n",
            " -2.45532431e-15+8.80640547e-16j -2.45532431e-15-8.80640547e-16j\n",
            " -2.69679335e-15+4.60224047e-16j -2.69679335e-15-4.60224047e-16j\n",
            "  2.57015375e-15+1.44148840e-16j  2.57015375e-15-1.44148840e-16j\n",
            "  2.34118497e-15+5.36717969e-16j  2.34118497e-15-5.36717969e-16j\n",
            "  2.44749023e-15+0.00000000e+00j -2.54468922e-15+1.14554611e-17j\n",
            " -2.54468922e-15-1.14554611e-17j  1.97021191e-15+9.23421810e-16j\n",
            "  1.97021191e-15-9.23421810e-16j  2.43331585e-15+2.29453565e-16j\n",
            "  2.43331585e-15-2.29453565e-16j -2.17056399e-15+3.18994082e-16j\n",
            " -2.17056399e-15-3.18994082e-16j  1.89799030e-15+6.72272487e-16j\n",
            "  1.89799030e-15-6.72272487e-16j  1.82941816e-15+4.22500418e-16j\n",
            "  1.82941816e-15-4.22500418e-16j  1.87832362e-15+7.99649735e-17j\n",
            "  1.87832362e-15-7.99649735e-17j  1.32499108e-15+7.07983661e-16j\n",
            "  1.32499108e-15-7.07983661e-16j -1.67364320e-15+4.88185503e-16j\n",
            " -1.67364320e-15-4.88185503e-16j -1.90352954e-15+0.00000000e+00j\n",
            " -1.57402918e-15+4.80075604e-16j -1.57402918e-15-4.80075604e-16j\n",
            " -1.75247647e-15+0.00000000e+00j -1.18343184e-15+7.40685684e-16j\n",
            " -1.18343184e-15-7.40685684e-16j  1.44190491e-15+1.80453491e-16j\n",
            "  1.44190491e-15-1.80453491e-16j -1.50382095e-15+1.28148737e-16j\n",
            " -1.50382095e-15-1.28148737e-16j  1.25144946e-15+0.00000000e+00j\n",
            "  8.15734900e-16+5.80861272e-16j  8.15734900e-16-5.80861272e-16j\n",
            " -6.96147403e-17+7.50858977e-16j -6.96147403e-17-7.50858977e-16j\n",
            " -9.59413800e-16+3.55719385e-16j -9.59413800e-16-3.55719385e-16j\n",
            " -1.22364996e-15+0.00000000e+00j -3.90896682e-16+5.83577144e-16j\n",
            " -3.90896682e-16-5.83577144e-16j  3.32951449e-16+6.94857670e-16j\n",
            "  3.32951449e-16-6.94857670e-16j  4.04861185e-16+6.25529695e-16j\n",
            "  4.04861185e-16-6.25529695e-16j  1.06787387e-15+0.00000000e+00j\n",
            " -1.14939527e-15+0.00000000e+00j -9.97480390e-16+4.21743177e-17j\n",
            " -9.97480390e-16-4.21743177e-17j -4.53768700e-16+4.31954999e-16j\n",
            " -4.53768700e-16-4.31954999e-16j  6.40388913e-16+2.84840397e-16j\n",
            "  6.40388913e-16-2.84840397e-16j -9.48022075e-17+4.50199745e-16j\n",
            " -9.48022075e-17-4.50199745e-16j -6.26131871e-16+7.75210013e-17j\n",
            " -6.26131871e-16-7.75210013e-17j  8.36058635e-16+1.15205498e-16j\n",
            "  8.36058635e-16-1.15205498e-16j  7.72053813e-16+0.00000000e+00j\n",
            "  3.52098135e-16+2.45423064e-16j  3.52098135e-16-2.45423064e-16j\n",
            "  1.92625656e-16+2.81455920e-16j  1.92625656e-16-2.81455920e-16j\n",
            " -3.46842545e-16+0.00000000e+00j -2.08715843e-16+0.00000000e+00j\n",
            "  1.55673025e-16+0.00000000e+00j  5.45051128e-17+8.94099963e-17j\n",
            "  5.45051128e-17-8.94099963e-17j -7.17309089e-17+0.00000000e+00j\n",
            "  2.72277675e-17+3.60034185e-17j  2.72277675e-17-3.60034185e-17j\n",
            " -1.64073444e-17+2.41288009e-17j -1.64073444e-17-2.41288009e-17j\n",
            "  1.96397491e-17+0.00000000e+00j -8.05233106e-18+0.00000000e+00j\n",
            "  1.45084318e-18+0.00000000e+00j  7.24222916e-23+0.00000000e+00j\n",
            "  0.00000000e+00+0.00000000e+00j  0.00000000e+00+0.00000000e+00j\n",
            "  0.00000000e+00+0.00000000e+00j  0.00000000e+00+0.00000000e+00j]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort eigenvectors by eigenvalues in descending order\n",
        "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "eigenvectors_sorted = eigenvectors[:, sorted_indices]\n",
        "print(\"eigenvectors_sorted Matrix:\", eigenvectors_sorted)\n",
        "\n",
        "# Calculate cumulative explained variance\n",
        "cumulative_variance_ratio = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
        "\n",
        "# Plot the explained variance\n",
        "plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, marker='o')\n",
        "plt.title('Cumulative Explained Variance')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Variance Ratio')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "dBnn6vza4Q7O",
        "outputId": "b998b91d-6d5d-499c-ab0b-69ed657066dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eigenvectors_sorted Matrix: [[-0.12009778+0.j -0.02214088+0.j  0.0101988 +0.j ...  0.10355088+0.j\n",
            "   0.03425   +0.j  0.19651486+0.j]\n",
            " [ 0.        +0.j  0.        +0.j  0.        +0.j ...  0.        +0.j\n",
            "   0.        +0.j  0.        +0.j]\n",
            " [ 0.11805094+0.j  0.02949244+0.j -0.02145011+0.j ...  0.07358539+0.j\n",
            "   0.01728749+0.j -0.06924291+0.j]\n",
            " ...\n",
            " [ 0.03471389+0.j -0.09196967+0.j -0.02841038+0.j ... -0.11069787+0.j\n",
            "  -0.02930262+0.j  0.01434951+0.j]\n",
            " [-0.08502399+0.j  0.10742367+0.j -0.03256746+0.j ...  0.00095551+0.j\n",
            "  -0.09381866+0.j -0.04007066+0.j]\n",
            " [ 0.0564812 +0.j  0.13326167+0.j -0.04450356+0.j ... -0.07822299+0.j\n",
            "   0.17365995+0.j  0.18999859+0.j]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/matplotlib/cbook/__init__.py:1335: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return np.asarray(x, float)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the number of components explaining, e.g., 95% of the variance\n",
        "num_components = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
        "print(f\"Number of components explaining 95% of the variance: {num_components}\")\n",
        "\n",
        "# Choose the number of principal components\n",
        "selected_components = eigenvectors_sorted[:, :num_components]\n",
        "print(\"Principal Components:\", selected_components)\n",
        "\n",
        "# Project the data onto the selected principal components\n",
        "data_pca = np.dot(data_standardized, selected_components)\n",
        "print(\"Data after PCA:\", data_pca.shape)\n",
        "print(\"Example of 2 samples:\", data_pca[:2, :])\n",
        "\n",
        "# Create DataFrames for visualization\n",
        "df_pca = pd.DataFrame(data_pca, columns=[f'Principal Component {i+1}' for i in range(num_components)])\n",
        "df_pca['Target'] = target\n",
        "\n",
        "# Plot data after PCA\n",
        "plt.figure(figsize=(12, 6))\n",
        "for class_label in np.unique(target):\n",
        "    plt.scatter(df_pca.loc[df_pca['Target'] == class_label, 'Principal Component 1'],\n",
        "                df_pca.loc[df_pca['Target'] == class_label, 'Principal Component 2'],\n",
        "                label=f'Class {class_label}', alpha=0.7)\n",
        "plt.title('Data after PCA')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "cSd86jXu4XpW",
        "outputId": "3b1b79c0-e428-4537-8521-4f8cb0d6f718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of components explaining 95% of the variance: 15\n",
            "Principal Components: [[-0.12009778+0.j -0.02214088+0.j  0.0101988 +0.j ... -0.00553192+0.j\n",
            "  -0.00238759+0.j -0.00309894+0.j]\n",
            " [ 0.        +0.j  0.        +0.j  0.        +0.j ...  0.        +0.j\n",
            "   0.        +0.j  0.        +0.j]\n",
            " [ 0.11805094+0.j  0.02949244+0.j -0.02145011+0.j ... -0.01933067+0.j\n",
            "  -0.00511254+0.j -0.02295348+0.j]\n",
            " ...\n",
            " [ 0.03471389+0.j -0.09196967+0.j -0.02841038+0.j ...  0.00895669+0.j\n",
            "   0.02737769+0.j  0.01307563+0.j]\n",
            " [-0.08502399+0.j  0.10742367+0.j -0.03256746+0.j ...  0.00030943+0.j\n",
            "   0.00485733+0.j -0.00561425+0.j]\n",
            " [ 0.0564812 +0.j  0.13326167+0.j -0.04450356+0.j ...  0.00681885+0.j\n",
            "   0.00765724+0.j -0.00195599+0.j]]\n",
            "Data after PCA: (71, 15)\n",
            "Example of 2 samples: [[ 8.60348070e+00+0.j  1.41186129e+00+0.j  1.92842733e-01+0.j\n",
            "  -5.22483321e+00+0.j -1.35797795e+00+0.j -3.45952976e-01+0.j\n",
            "  -7.92075739e-02+0.j  7.98728943e-02+0.j  1.42234280e-02+0.j\n",
            "   8.93110356e-02+0.j -4.29654536e-02+0.j  2.64017472e-01+0.j\n",
            "  -1.30584879e-01+0.j -1.76755393e-01+0.j  2.60013973e-01+0.j]\n",
            " [ 8.60193201e+00+0.j  1.42307905e+00+0.j  1.54388310e-01+0.j\n",
            "  -5.26060988e+00+0.j -1.38065474e+00+0.j -4.55112185e-01+0.j\n",
            "  -7.12405271e-02+0.j  1.86392723e-01+0.j -3.28308146e-03+0.j\n",
            "   4.90655023e-02+0.j -6.44752788e-02+0.j  3.13357660e-01+0.j\n",
            "  -1.01052763e-01+0.j -1.55057475e-01+0.j  2.85268602e-01+0.j]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/matplotlib/collections.py:192: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  offsets = np.asanyarray(offsets, float)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/AAAAIjCAYAAACkgvA7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSyUlEQVR4nOzdeXhU9d3+8fvMTGayThIgAdGQACFsArKoSGqBFkSlWBTXoog8tFBBBJSKRYsb4ILiDpanTcQqUv2BleKGgPgACsgui+wJyBKWZEIIWWbO+f0xMjImQAIJYeD9uq4pmbN+Zky5uM93MyzLsgQAAAAAAM5rtpouAAAAAAAAnB4BHgAAAACAEECABwAAAAAgBBDgAQAAAAAIAQR4AAAAAABCAAEeAAAAAIAQQIAHAAAAACAEEOABAAAAAAgBBHgAAAAAAEIAAR4AAJyR5cuXq1OnToqKipJhGFq9enVNlwQAwAWNAA8AQDXJzMyUYRiBV3h4uOrXr68ePXro1Vdf1ZEjR8742kuWLNETTzyhvLy8qiu4EkpLS3Xbbbfp8OHDmjRpkt555x0lJyfrzTffVGZm5jmtJSUlJeh7TkxM1LXXXqtZs2aVe/ysWbN0ww03qE6dOnI6napfv75uv/12zZ8/v9zjP/nkExmGofr168s0zer8KAAAnJJhWZZV00UAAHAhyszM1H333aennnpKDRs2VGlpqfbt26evvvpKc+fOVYMGDfTxxx+rdevWlb72xIkTNWrUKO3YsUMpKSlVX/xpbNq0Sc2bN9fUqVM1cODAwPbLL79cderU0VdffXXOaklJSVF8fLweeughSdKePXv01ltvafv27Zo8ebIGDx4sSbIsSwMGDFBmZqbatm2rW2+9VfXq1dPevXs1a9YsrVixQosXL1anTp2Crt+3b18tWbJEO3fu1Ny5c9WtW7dz9tkAADiRo6YLAADgQnfDDTeoQ4cOgfePPvqo5s+fr9/97ne66aabtHHjRkVERNRghZWXk5MjSYqLi6v2e3m9XpmmKafTedJjLr30Ut19992B9/369VNqaqomTZoUCPAvvviiMjMzNXz4cL300ksyDCNw/JgxY/TOO+/I4Qj+p9HRo0f1n//8RxMmTFBGRobeffddAjwAoMbQhR4AgBrwm9/8Ro8//riysrL0r3/9K7B97dq16t+/vxo1aqTw8HDVq1dPAwYM0KFDhwLHPPHEExo1apQkqWHDhoGu4zt37pQkZWRk6De/+Y0SExPlcrnUokULTZ48uUJ1VeT+/fv3V+fOnSVJt912mwzDUJcuXZSSkqL169dr4cKFgZq6dOkSOC8vL0/Dhw9XUlKSXC6XUlNT9dxzzwV1S9+5c6cMw9DEiRP18ssvq3HjxnK5XNqwYUOlvt969eqpefPm2rFjhyTp2LFjmjBhgpo1a6aJEycGhffj7rnnHl111VVB22bNmqVjx47ptttu05133qmZM2eqqKioUrUAAFBVaIEHAKCG3HPPPfrrX/+qL774Qn/84x8lSXPnztX27dt13333qV69elq/fr3+/ve/a/369fr2229lGIZuueUWbd68WdOnT9ekSZNUp04dSVJCQoIkafLkyWrZsqVuuukmORwOzZ49W/fff79M09SQIUNOWVNF7j9o0CBdeumlGj9+vIYNG6Yrr7xSdevW1dGjR/XAAw8oOjpaY8aMkSTVrVtXklRYWKjOnTvrxx9/1KBBg9SgQQMtWbJEjz76qPbu3auXX345qI6MjAwVFRXpT3/6k1wul2rVqlWp77a0tFS7du1S7dq1JUmLFi3S4cOHNXz4cNnt9gpf591331XXrl1Vr1493XnnnRo9erRmz56t2267rVL1AABQJSwAAFAtMjIyLEnW8uXLT3pMbGys1bZt28D7wsLCMsdMnz7dkmR9/fXXgW0vvPCCJcnasWNHmePLu0aPHj2sRo0anbbmit5/wYIFliTrgw8+CDq2ZcuWVufOnctc4+mnn7aioqKszZs3B20fPXq0ZbfbrezsbMuyLGvHjh2WJMvtdls5OTmnrdeyLCs5Odm67rrrrAMHDlgHDhyw1qxZY915552WJOuBBx6wLMuyXnnlFUuSNWvWrApd07Isa//+/ZbD4bCmTp0a2NapUyfr97//fYWvAQBAVaILPQAANSg6OjpoNvoTx8IXFRXp4MGD6tixoyRp5cqVFbrmidfweDw6ePCgOnfurO3bt8vj8VT43DO9f3k++OADXXvttYqPj9fBgwcDr27dusnn8+nrr78OOr5Pnz6BHgUV8cUXXyghIUEJCQlq06aNPvjgA91zzz167rnnJEn5+fmSpJiYmApf8/3335fNZlOfPn0C2+666y59+umnys3NrfB1AACoKnShBwCgBhUUFCgxMTHw/vDhw3ryySf1/vvvByaKO+504fu4xYsXa+zYsfrmm29UWFhY5hqxsbEnPbcq7l+eLVu2aO3atScN5b+8V8OGDSt1/auvvlrPPPOMDMNQZGSkmjdvHjTBntvtlqRKLd33r3/9S1dddZUOHToUmAOgbdu2Kikp0QcffKA//elPlaoRAICzRYAHAKCG7N69Wx6PR6mpqYFtt99+u5YsWaJRo0bpiiuuUHR0tEzT1PXXX1+hNci3bdum3/72t2rWrJleeuklJSUlyel06pNPPtGkSZNOe42zvf/JmKap7t276y9/+Uu5+9PS0oLeV3ZW/jp16pxydvhmzZpJktatW6fevXuf9npbtmzR8uXLJUlNmjQps//dd98lwAMAzjkCPAAANeSdd96RJPXo0UOSlJubq3nz5unJJ5/U3/72t8BxW7ZsKXNuebOoS9Ls2bNVXFysjz/+WA0aNAhsX7BgwWnrqcz9T+ZkdTVu3FgFBQU1tgTbr371K8XHx2v69On661//etqJ7N59912FhYXpnXfeKXPsokWL9Oqrryo7OzvoOwYAoLoxBh4AgBowf/58Pf3002rYsKH69u0rSYGgaFlW0LG/nKFdkqKioiT5l2Y7UXnX8Hg8ysjIOG1Nlbn/yURFRZWpSfK37H/zzTf6/PPPy+zLy8uT1+ut8D3ORGRkpB555BFt3LhRjzzySJnPKPm7zC9btkySP8Bfe+21uuOOO3TrrbcGvY4v4Td9+vRqrRkAgF+iBR4AgGr26aefatOmTfJ6vdq/f7/mz5+vuXPnKjk5WR9//LHCw8Ml+cdp//rXv9bzzz+v0tJSXXrppfriiy8Ca5mfqH379pKkMWPG6M4771RYWJh69eql6667Tk6nU7169dKgQYNUUFCgqVOnKjExUXv37j1lnZW5/8m0b99ekydP1jPPPKPU1FQlJibqN7/5jUaNGqWPP/5Yv/vd79S/f3+1b99eR48e1bp16/Thhx9q586dgeXwqsuoUaO0fv16vfjii1qwYIFuvfVW1atXT/v27dNHH32kZcuWacmSJVq6dKm2bt2qoUOHlnudSy+9VO3atdO7776rRx55pFprBgDgRAR4AACq2fHu6E6nU7Vq1VKrVq308ssv67777iszK/p7772nBx54QG+88YYsy9J1112nTz/9VPXr1w867sorr9TTTz+tKVOm6LPPPpNpmtqxY4eaNm2qDz/8UI899pgefvhh1atXT3/+85+VkJCgAQMGnLbWit7/VJ81KytLzz//vI4cOaLOnTvrN7/5jSIjI7Vw4UKNHz9eH3zwgaZNmya32620tDQ9+eSTp5xYr6rYbDZNmzZNv//97/X3v/9dEydOVH5+vhISEgIPLq655hoNGzZMktSrV6+TXqtXr1564okntHbtWrVu3braawcAQJIMq7w+ZAAAAAAA4LzCGHgAAAAAAEIAAR4AAAAAgBBAgAcAAAAAIAQQ4AEAAAAACAEEeAAAAAAAQgABHgAAAACAEMA68L9gmqb27NmjmJgYGYZR0+UAAAAAAC5wlmXpyJEjql+/vmy2k7ezE+B/Yc+ePUpKSqrpMgAAAAAAF5ldu3bpsssuO+l+AvwvxMTESPJ/cW63u4arAQAAAABc6PLz85WUlBTIoydDgP+F493m3W43AR4AAAAAcM6cbhg3k9gBAAAAABACCPAAAAAAAIQAAjwAAAAAACGAMfAAAAAAaoxlWfJ6vfL5fDVdClBt7Ha7HA7HWS9VToAHAAAAUCNKSkq0d+9eFRYW1nQpQLWLjIzUJZdcIqfTecbXIMADAAAAOOdM09SOHTtkt9tVv359OZ3Os26dBM5HlmWppKREBw4c0I4dO9SkSRPZbGc2mp0ADwAAAOCcKykpkWmaSkpKUmRkZE2XA1SriIgIhYWFKSsrSyUlJQoPDz+j6zCJHQAAAIAac6YtkUCoqYrfdf7fAgAAAABACCDAAwAAAAAQAgjwAAAAAFDFDMPQRx99VNNl4AJDgAcAAACASti3b58eeOABNWrUSC6XS0lJSerVq5fmzZtX06WdVElJiV544QW1a9dOUVFRio2NVZs2bfTYY49pz54957ye8+0Bx9///nd16dJFbrdbhmEoLy+vpksqFwEeAAAAQMgyTUub9uVr6fZD2rQvX6ZpVev9du7cqfbt22v+/Pl64YUXtG7dOn322Wfq2rWrhgwZUq33PlPFxcXq3r27xo8fr/79++vrr7/WunXr9Oqrr+rgwYN67bXXarrEGldYWKjrr79ef/3rX2u6lFMiwF8oTFPav17audj/p2nWdEUAAABAtVqRdVjDZ6zWyBlrNGbWOo2csUbDZ6zWiqzD1XbP+++/X4ZhaNmyZerTp4/S0tLUsmVLjRw5Ut9+++1Jz3vkkUeUlpamyMhINWrUSI8//rhKS0sD+9esWaOuXbsqJiZGbrdb7du313fffSdJysrKUq9evRQfH6+oqCi1bNlSn3zySYVrnjRpkhYtWqT58+dr2LBhat++vRo0aKDOnTtrypQpGj9+fOBY0zQ1YcIENWzYUBEREWrTpo0+/PDDwP6vvvpKhmFo3rx56tChgyIjI9WpUyf98MMPQfecPHmyGjduLKfTqaZNm+qdd94J7EtJSZEk3XzzzTIMQykpKdq5c6dsNlvgMx/38ssvKzk5WaZpBu49Z84ctW7dWuHh4erYsaO+//77oHMWLVqka6+9VhEREUpKStKwYcN09OjRU35Hw4cP1+jRo9WxY8cKf681gQB/IcheKs38ozRrkPTf4f4/Z/7Rvx0AAAC4AK3IOqxxczbq+x89coc7dFl8pNzhDq3f49G4ORurJcQfPnxYn332mYYMGaKoqKgy++Pi4k56bkxMjDIzM7Vhwwa98sormjp1qiZNmhTY37dvX1122WVavny5VqxYodGjRyssLEySNGTIEBUXFwdazp977jlFR0dXuO7p06ere/fuatu2bbn7DcMI/DxhwgRNmzZNU6ZM0fr16zVixAjdfffdWrhwYdA5Y8aM0YsvvqjvvvtODodDAwYMCOybNWuWHnzwQT300EP6/vvvNWjQIN13331asGCBJGn58uWSpIyMDO3du1fLly9XSkqKunXrpoyMjKD7ZGRkqH///kFLsI0aNUovvviili9froSEBPXq1SvwMGTbtm26/vrr1adPH61du1YzZszQokWLNHTo0Ap/X+czR00XgLOUvVT6Yox0LE+KqSs5IiTvMWnvWv/268ZJDa7++XjTlA5s9B8fESclNJdYexMAAAAhxDQtvb0kS3mFpUqpHRkIoFEuhyKddmUdLtS0JVlqmxQvm804zdUqbuvWrbIsS82aNav0uY899ljg55SUFD388MN6//339Ze//EWSlJ2drVGjRgWu3aRJk8Dx2dnZ6tOnj1q1aiVJatSoUaXuvXnzZnXp0iVo280336y5c+dKklq3bq0lS5aouLhY48eP15dffqlrrrkmcK9FixbprbfeUufOnQPnjxs3LvB+9OjR6tmzp4qKihQeHq6JEyeqf//+uv/++yUp0Dth4sSJ6tq1qxISEiT5H3jUq1cvcM2BAwdq8ODBeumll+RyubRy5UqtW7dO//nPf4JqHzt2rLp37y5Jevvtt3XZZZdp1qxZuv322zVhwgT17dtXw4cPD3yPr776qjp37qzJkycrPDy8Ut/d+YbkFspMU1r2d38Yr9VIckZLhk2yLCk8VirI8e8/3p2elnoAAABcADbnHNHWnAIlxriCWo8lf2tyQrRLW3IKtDnnSJXe17LOfHz9jBkzlJ6ernr16ik6OlqPPfaYsrOzA/tHjhypgQMHqlu3bnr22We1bdu2wL5hw4bpmWeeUXp6usaOHau1a9ee1eeQpDfffFOrV6/WgAEDVFhYKMn/gKKwsFDdu3dXdHR04DVt2rSgeiR/6D/ukksukSTl5ORIkjZu3Kj09PSg49PT07Vx48ZT1tS7d2/Z7XbNmjVLkpSZmamuXbsGutwfd/zhgiTVqlVLTZs2DVx7zZo1yszMDKq/R48eMk1TO3bs0Pjx44P2nfjfIBQQ4EPZgY3SwR/8Le+GIR3Llfat9b9yNkhHD0hb50pr//1zS/3eNf5wH5fs//N4Sz0hHgAAACHCU1iqEq9P4WH2cveHh9lV4vXJU1ha7v4z1aRJExmGoU2bNlXqvG+++UZ9+/bVjTfeqP/+979atWqVxowZo5KSksAxTzzxhNavX6+ePXtq/vz5atGiRSDIDhw4UNu3b9c999yjdevWqUOHDpWaeK5JkyZlxqhfcsklSk1NVa1atQLbCgoKJElz5szR6tWrA68NGzYEjYOXFOjeL/3cBd88y3m4nE6n+vXrp4yMDJWUlOi9994L6ppfEQUFBRo0aFBQ/WvWrNGWLVvUuHFjDR48OGhf/fr1z6rmc40AH8qO5UneYn+3+WO50oFNUlG+ZHNIYRGS3SmVFEqLXpK+mhDcUm+z+/+s1VA65pGWT2XiOwAAAISE2MgwOR12FZX6yt1fVOqT02FXbGRYufvPVK1atdSjRw+98cYb5U6KdrKlx5YsWaLk5GSNGTNGHTp0UJMmTZSVlVXmuLS0NI0YMUJffPGFbrnllqDx4ElJSRo8eLBmzpyphx56SFOnTq1w3XfddZfmzp2rVatWnfK4Fi1ayOVyKTs7W6mpqUGvpKSkCt+vefPmWrx4cdC2xYsXq0WLFoH3YWFh8vnK/vcbOHCgvvzyS7355pvyer265ZZbyhxz4mSBubm52rx5s5o3by5JateunTZs2FCm/tTUVDmdTtWqVStom8MRWqPKQ6taBIuIkxwuqfSYlJct+bySM/Ln/YYhOcL9ob5gv1T3cv+2X3JFST+ukDb9V2r2O8bEAwAA4LyWlhij1MRord/jUaTTHtSN3rIsHSgo1uX1Y5WWGFPl937jjTeUnp6uq666Sk899ZRat24tr9eruXPnavLkyeV2E2/SpImys7P1/vvv68orr9ScOXMCreuSdOzYMY0aNUq33nqrGjZsqN27d2v58uXq06ePJP8M6TfccIPS0tKUm5urBQsWBAJrRYwYMUJz5szRb3/7W40dO1bXXnut4uPjtXnzZn366aey2/09GWJiYvTwww9rxIgRMk1Tv/rVr+TxeLR48WK53W7de++9FbrfqFGjdPvtt6tt27bq1q2bZs+erZkzZ+rLL78MHJOSkqJ58+YpPT1dLpdL8fHxkvzhv2PHjnrkkUc0YMAARURElLn+U089pdq1a6tu3boaM2aM6tSpo969e0vyz/bfsWNHDR06VAMHDlRUVJQ2bNiguXPn6vXXXz9pzfv27dO+ffu0detWSdK6desUExOjBg0aBPVSqGkktVB0fMm4wsNSdD3Js0sqPiI5nD8fY1mSt0RyRUtRtf0h3/rFE67jXe4PbpHydklfjmVMPAAAAM57NpuhezslKzYiTFmHC3W02CufaelosVdZhwsVGxGmfp2Sq3QCu+MaNWqklStXqmvXrnrooYd0+eWXq3v37po3b54mT55c7jk33XSTRowYoaFDh+qKK67QkiVL9Pjjjwf22+12HTp0SP369VNaWppuv/123XDDDXryySclST6fT0OGDFHz5s11/fXXKy0tTW+++WaFaw4PD9e8efP0yCOPKCMjQ7/61a/UvHlzDR8+XOnp6froo48Cxz799NN6/PHHNWHChMD95syZo4YNG1b4fr1799Yrr7yiiRMnqmXLlnrrrbeUkZERNJHeiy++qLlz5yopKanM7Pj/8z//o5KSkpN2n3/22Wf14IMPqn379tq3b59mz54tp9OfhVq3bq2FCxdq8+bNuvbaa9W2bVv97W9/O21X+SlTpqht27b64x//KEn69a9/rbZt2+rjjz+u8Oc+FwzrbGZiuADl5+crNjZWHo9Hbre7psspK3upf2K6gz/4u8+bXv9Y99JjP3WNd/iDurdEsodJCU0lGdKeVVKdNCn2Uv91juVKB36QfKX+7vSWKdVpIhUflSJiy85eDwAAAFShoqIi7dixQw0bNjzjmcFXZB3W20uytDWnQCVef7f5JonR6tcpWe2Tz59WU1TO008/rQ8++KDMZH1fffWVunbtqtzc3FMu2Xe+OtXvfEVzKF3oQ8nJlowrOeof615a6J+F3rBLrhgpPlmKiPe3zoeFS8X5kvXTk6e8bH94D4vwh/9wtxSVKEVJOrzDPyb+sivpTg8AAIDzVvvkWmqbFK/NOUfkKSxVbGSY0hJjqqXlHdWvoKBAO3fu1Ouvv65nnnmmpss5L5HOQkV5S8Ydn4guNlmy5A/klvTT//hZlnQkx9+6LkPas1rK3ekP9YbNH/4NQ4qs4z/eMKSYRP+EeAdOvcwDAAAAUNNsNkPN6rl1daPaalbPTXgPYUOHDlX79u3VpUuXSs8+f7GgBT5U/HLJOMuSSgr84+A9uyW7XfL9NIu8zeFvbd+/wd9K7yuSCvb+1OXeJx3NkWT5W+oNw/9z3k6p8KAU10ByuSVvjv9hAQAAAACcA5mZmcrMzDzp/i5duuhiHwFOgA8Vv1wyLi/b34peekyBMG4P889Cb/7UEu8r8nexl+EP9c4o/7VKCvxj5y1TCov2z2Rv+fyz1R/4wR/iHS7/LPcAAAAAgPMCAT5UHF8yrmD/z+PXbfafdtr8LeuGpPA4/3h2e5h/dvmifP968K5o/6GW5e86738j+Yr94+MNhxRm9z8QOLxDSushJVR8aQoAAAAAQPUiwIeKhOZS7TRpyxf+1vKwn1raJfmb203/H3lZ/n3H14eXJdlP+M9s+fxhXzb/Ob5Sf8u+3enfZ5n+c1K7M4EdAAAAAJxHSGihwmaTmlwnWV5/K7rlk2Sc8LP83egl/7j2kgJ/67rk7z5/nPXTOHnD9tPL8HenLz3m/zM8VoqsLcUlnbOPBgAAAAA4PVrgQ0lckn+2eF+pVHpU8noVmHHesPsDuWX6/7SHS94i/35fqT+o2xwndJ+XJMPfUl8nzd8Cbw/zby7KlwoPSTsX+7vuJzSnNR4AAAAAahgBPpRExPlfrlhJllTkkQ5u/bkrvWX5t1um5CuRf1C89VPYL/IHeEe4f+y8r9S/PzxWij5hZvucDf5rLXzOfw2HS6rTVLrqT1KDq2vgQwMAAAAAJLrQh5aE5v4wXZDjX/89LPLnteAN289d6U2vf5y7zSF/iDd+DvUlBT8FffnHxkcl+PcVH5H2rpaOHpC8Jf5gH5fs/3PvWumLMVL20hr64AAAAEBoMQxDH330UU2XgQsMAT6U2Gz+lvCIWP9M8WapJNPfwm56fzomzP+zYfPPPB8W4Z+V/viM9cdDfv0rpOR0SZZ0YJO073v/mvKmVyotlA5v968l74yWajWUjnmk5VMl06yBDw4AAACcP/bt26cHHnhAjRo1ksvlUlJSknr16qV58+bVdGknVVJSohdeeEHt2rVTVFSUYmNj1aZNGz322GPas2fPOa/nfHrAcfjwYT3wwANq2rSpIiIi1KBBAw0bNkwej6emSyuDLvShpsHV0nXjpGV/l35c4Z9B3jL9wd0Z6W9dLy7wH1t6TIqIl+q28re8F+dLpcWSLKnXa1LdltK6f0uLJv3Uau/1j4M3jJ/XhE9o6r9GTKI/6B/Y6D8PAAAAOB+Ypv/fqMfyzsn8TTt37lR6erri4uL0wgsvqFWrViotLdXnn3+uIUOGaNOmTdV27zNVXFys6667TmvXrtWTTz6p9PR0JSQkaMeOHZo+fbpee+01TZgwoabLrDF79uzRnj17NHHiRLVo0UJZWVkaPHiw9uzZow8//LCmywtCC3woanC1dPNbUu1UKaK2v5Xc7vxpgrqfxr3L8nejj03y/wUW7pZiL5NqpfjfF+f7r7Vlrv8492X+9zaH/xUW4R8nn5ftfyjgiPA/LDiWVyMfGQAAACgje6k084/SrEHSf4f7/5z5x2od+nn//ffLMAwtW7ZMffr0UVpamlq2bKmRI0fq22+/Pel5jzzyiNLS0hQZGalGjRrp8ccfV2lpaWD/mjVr1LVrV8XExMjtdqt9+/b67rvvJElZWVnq1auX4uPjFRUVpZYtW+qTTz6pcM2TJk3SokWLNH/+fA0bNkzt27dXgwYN1LlzZ02ZMkXjx48PHGuapiZMmKCGDRsqIiJCbdq0CQqxX331lQzD0Lx589ShQwdFRkaqU6dO+uGHH4LuOXnyZDVu3FhOp1NNmzbVO++8E9iXkpIiSbr55ptlGIZSUlK0c+dO2Wy2wGc+7uWXX1ZycrJM0wzce86cOWrdurXCw8PVsWNHff/990HnLFq0SNdee60iIiKUlJSkYcOG6ejRoyf9fi6//HL9v//3/9SrVy81btxYv/nNbzRu3DjNnj1bXq+3wt/zuUCAD1UHf5AK9kmJTf0t4uFufwu6r+SnGeft/tb04zPLH+c95p+YLiLO/6Ty4A9STF3J4fQH+8CSdIZ/W0mB/3XieQAAAEBNy17qn6dp75pzNn/T4cOH9dlnn2nIkCGKiooqsz8uLu6k58bExCgzM1MbNmzQK6+8oqlTp2rSpEmB/X379tVll12m5cuXa8WKFRo9erTCwvz/lh8yZIiKi4v19ddfa926dXruuecUHR1d4bqnT5+u7t27q23btuXuNwwj8POECRM0bdo0TZkyRevXr9eIESN09913a+HChUHnjBkzRi+++KK+++47ORwODRgwILBv1qxZevDBB/XQQw/p+++/16BBg3TfffdpwYIFkqTly5dLkjIyMrR3714tX75cKSkp6tatmzIyMoLuk5GRof79+8t2Qq+KUaNG6cUXX9Ty5cuVkJCgXr16BR6GbNu2Tddff7369OmjtWvXasaMGVq0aJGGDh1a4e9Lkjwej9xutxyO86vT+vlVDSruWJ6/RdwR4W+BD4/7ae33Ev/4+OKjkoyfZpv/iWVJR3Kk+m38XYuyv/n5GobNf52ifMn506+FYZfMEv81j3l+Pg8AAACoSabpH1J6LE+q1cjf+CT9NH9TlP/fw8unSpddWaXd6bdu3SrLstSsWbNKn/vYY48Ffk5JSdHDDz+s999/X3/5y18kSdnZ2Ro1alTg2k2aNAkcn52drT59+qhVq1aSpEaNGlXq3ps3b1aXLl2Ctt18882aO3euJKl169ZasmSJiouLNX78eH355Ze65pprAvdatGiR3nrrLXXu3Dlw/rhx4wLvR48erZ49e6qoqEjh4eGaOHGi+vfvr/vvv1+SAr0TJk6cqK5duyohIUGS/4FHvXr1AtccOHCgBg8erJdeekkul0srV67UunXr9J///Ceo9rFjx6p79+6SpLfffluXXXaZZs2apdtvv10TJkxQ3759NXz48MD3+Oqrr6pz586aPHmywsPDT/t9HTx4UE8//bT+9Kc/VfQrPmdogQ9VEXH+FnHvMf97w5BcMVJkbal2Y8lu/2lce6m/i3xJgf8vsog46co/+v8iO/EahiHFNfDPTF9S+POYeMkf+k88DwAAAKhJJ/YkPaH1WJL//YnzN1Uh6/hqTmdgxowZSk9PV7169RQdHa3HHntM2dnZgf0jR47UwIED1a1bNz377LPatm1bYN+wYcP0zDPPKD09XWPHjtXatWvP6nNI0ptvvqnVq1drwIABKiwslOR/QFFYWKju3bsrOjo68Jo2bVpQPZI/9B93ySWXSJJycnIkSRs3blR6enrQ8enp6dq48dT/PXr37i273a5Zs2ZJkjIzM9W1a9dAl/vjjj9ckKRatWqpadOmgWuvWbNGmZmZQfX36NFDpmlqx44dGj9+fNC+E/8bSFJ+fr569uypFi1a6IknnjhlvTWBNBaqji8pdyTn52XhjguP8088F5340zj2LP+a8fXbSNc98/N67r+8RkS8lNDM3x3fV+qf3d7ukJKulLo9IRXsl76dIm34WPKdX2NBAAAAcBE5sTdqeapp/qYmTZrIMIxKT1T3zTffqG/fvrrxxhv13//+V6tWrdKYMWNUUlISOOaJJ57Q+vXr1bNnT82fP18tWrQIBNmBAwdq+/btuueee7Ru3Tp16NBBr732WqXq/uUY9UsuuUSpqamqVatWYFtBgX8y7Dlz5mj16tWB14YNG8pM5na8e7/0cxd88yxXrHI6nerXr58yMjJUUlKi9957L6hrfkUUFBRo0KBBQfWvWbNGW7ZsUePGjTV48OCgffXr1w+ce+TIEV1//fWKiYnRrFmzgj7j+YIu9KHq+JJyX4zxt6zHJP70F9UxfyCPuUTq/pQ/jJ9sRs7yruFy+7sheXb7J7L71Qh/d/xZg/xrxJs+//j6qATpVyOlKyv3fygAAADgrJ3Yk9RZzljwapq/qVatWurRo4feeOMNDRs2rMw4+Ly8vHLHwS9ZskTJyckaM2ZMYFtWVlaZ49LS0pSWlqYRI0borrvuUkZGhm6++WZJUlJSkgYPHqzBgwfr0Ucf1dSpU/XAAw9UqO677rpLjz32mFatWnXScfCS1KJFC7lcLmVnZwd1l6+s5s2ba/Hixbr33nsD2xYvXqwWLVoE3oeFhcnn85U5d+DAgbr88sv15ptvyuv16pZbbilzzLfffqsGDRpIknJzc7V582Y1b+4f6tuuXTtt2LBBqamp5dZWq1atoIcWx+Xn56tHjx5yuVz6+OOPK9TVviYQ4EPZiUvKHfxB8ub4/6Kq38bf3f14S/uZXCPpKv819q+Xvnxc8pb4A31YmL9b/pF90tyfxvEQ4gEAAHAuHe9Junetf8z7id3ofznvUxV74403lJ6erquuukpPPfWUWrduLa/Xq7lz52ry5MnldhNv0qSJsrOz9f777+vKK6/UnDlzAq3rknTs2DGNGjVKt956qxo2bKjdu3dr+fLl6tOnjyRp+PDhuuGGG5SWlqbc3FwtWLAgEFgrYsSIEZozZ45++9vfauzYsbr22msVHx+vzZs369NPP5Xdbpfkn2jv4Ycf1ogRI2Sapn71q1/J4/Fo8eLFcrvdQYH8VEaNGqXbb79dbdu2Vbdu3TR79mzNnDlTX375ZeCYlJQUzZs3T+np6XK5XIqPj5fkD/8dO3bUI488ogEDBigiomwvi6eeekq1a9dW3bp1NWbMGNWpU0e9e/eW5J/tv2PHjho6dKgGDhyoqKgobdiwQXPnztXrr79ebr35+fm67rrrVFhYqH/961/Kz89Xfr5/1a6EhITA93M+IMCHugZX+yfnOJu1L092DcuU/t//+MN7eOzPfzHaXP5l64o8/jXk2/Xzd7UHAAAAzoXT9UatxvmbGjVqpJUrV2rcuHF66KGHtHfvXiUkJKh9+/aaPHlyuefcdNNNGjFihIYOHari4mL17NlTjz/+eGCMtd1u16FDh9SvXz/t379fderU0S233KInn3xSkuTz+TRkyBDt3r1bbrdb119/fdAM9qcTHh6uefPm6eWXX1ZGRoYeffRRmaaphg0b6oYbbtCIESMCxz799NNKSEjQhAkTtH37dsXFxaldu3b661//WuH79e7dW6+88oomTpyoBx98UA0bNlRGRkbQRHovvviiRo4cqalTp+rSSy/Vzp07A/v+53/+R0uWLDlp9/lnn31WDz74oLZs2aIrrrhCs2fPltPplOQfm79w4UKNGTNG1157rSzLUuPGjXXHHXectN6VK1dq6VL/qgW/bLnfsWNHmTH4NcmwzmYmhgtQfn6+YmNjA8sGXNQ2fOxfR9Pu9LfK/5K32D9D/S1TpRY3nfv6AAAAELKKioq0Y8cONWzY8My7K2cvPaEnabH/36wJzSreGxXnpaeffloffPBBmcn6vvrqK3Xt2lW5ubmnXLLvfHWq3/mK5lCaTXFy+Xv8Y95PNnmDLUwqPeY/DgAAADjXqqI3Ks4bBQUF2rlzp15//XU988wzNV3OeYnfbJycu75/wjqztPz9Zql/v7t++fsBAACA6mazSXVbSinp/j8J7yFr6NChat++vbp06VLp2ecvFrTA4+Sa3uifbf7IPn83+l9ODlJ6zD/bfdMba65GAAAAABeEzMxMZWZmnnR/ly5ddLGPAOfxFE7O7vAvFef4acI6b7Fkmv4/izz+MUa/GsEEdgAAAABwDpC8cGrHl4hb9JJ/HfjSY/5u8zGX+MM7S8gBAAAAwDlBgMfpXTnAv1TcD5/4J6xz1/d3m6flHQAAAADOGRIYKsbuYKk4AAAAAKhBjIEHAAAAACAEEOABAAAAAAgBBHgAAAAAqGKGYeijjz6q6TJwgSHAAwAAAAhZpmVqc+5mfbfvO23O3SzTMqv9nvv27dMDDzygRo0ayeVyKSkpSb169dK8efOq/d5nqqSkRC+88ILatWunqKgoxcbGqk2bNnrssce0Z8+ec17P+faAIyUlRYZh6P333y+zr2XLljIMI2iN+r///e/q0qWL3G63DMNQXl7eOamTSewAAAAAhKTVOav13qb3tCNvh0rMEjltTjWMa6g/NPuDrki8olruuXPnTqWnpysuLk4vvPCCWrVqpdLSUn3++ecaMmSINm3aVC33PRvFxcW67rrrtHbtWj355JNKT09XQkKCduzYoenTp+u1117ThAkTarrMGpeUlKSMjAzdeeedgW3ffvut9u3bp6ioqKBjCwsLdf311+v666/Xo48+es5qpAUeAAAAQMhZnbNaE7+bqI2HNirGGaNLoy9VjDNGmw5t0sTvJmp1zupque/9998vwzC0bNky9enTR2lpaWrZsqVGjhypb7/99qTnPfLII0pLS1NkZKQaNWqkxx9/XKWlpYH9a9asUdeuXRUTEyO326327dvru+++kyRlZWWpV69eio+PV1RUlFq2bKlPPvmkwjVPmjRJixYt0vz58zVs2DC1b99eDRo0UOfOnTVlyhSNHz8+cKxpmpowYYIaNmyoiIgItWnTRh9++GFg/1dffSXDMDRv3jx16NBBkZGR6tSpk3744Yege06ePFmNGzeW0+lU06ZN9c477wT2paSkSJJuvvlmGYahlJQU7dy5UzabLfCZj3v55ZeVnJws0zQD954zZ45at26t8PBwdezYUd9//33QOYsWLdK1116riIgIJSUladiwYTp69Ohpv6e+fftq4cKF2rVrV2DbP//5T/Xt21cOR3Db9/DhwzV69Gh17NjxtNetSgR4AAAAACHFtEy9t+k9eYo9ahDTQJFhkbIZNkWGRSopJkn5xfmavml6lXenP3z4sD777DMNGTKkTIusJMXFxZ303JiYGGVmZmrDhg165ZVXNHXqVE2aNCmwv2/fvrrsssu0fPlyrVixQqNHj1ZYWJgkaciQISouLtbXX3+tdevW6bnnnlN0dHSF654+fbq6d++utm3blrvfMIzAzxMmTNC0adM0ZcoUrV+/XiNGjNDdd9+thQsXBp0zZswYvfjii/ruu+/kcDg0YMCAwL5Zs2bpwQcf1EMPPaTvv/9egwYN0n333acFCxZIkpYvXy5JysjI0N69e7V8+XKlpKSoW7duysjICLpPRkaG+vfvL5vt5+g6atQovfjii1q+fLkSEhLUq1evwMOQbdu26frrr1efPn20du1azZgxQ4sWLdLQoUNP+z3VrVtXPXr00Ntvvy3J38o+Y8aMoM9W0wjwAAAAAELK1ryt2pG3QwkRCUHhU/KH0ToRdbQ9b7u25m2t2vtu3SrLstSsWbNKn/vYY4+pU6dOSklJUa9evfTwww/r3//+d2B/dna2unXrpmbNmqlJkya67bbb1KZNm8C+9PR0tWrVSo0aNdLvfvc7/frXv67wvTdv3qymTZsGbbv55psVHR2t6OhoderUSZK/q/348eP1z3/+Uz169FCjRo3Uv39/3X333XrrrbeCzh83bpw6d+6sFi1aaPTo0VqyZImKiookSRMnTlT//v11//33Ky0tTSNHjtQtt9yiiRMnSpISEhIk+R941KtXL/B+4MCBmj59uoqLiyVJK1eu1Lp163TfffcF3Xvs2LHq3r27WrVqpbffflv79+/XrFmzJPkfQPTt21fDhw9XkyZN1KlTJ7366quaNm1aoL5TGTBggDIzM2VZlj788EM1btxYV1xxRYW/6+pGgAcAAAAQUvKL81VilijcEV7ufpfDpRKzRPnF+VV6X8uyzvjcGTNmKD09XfXq1VN0dLQee+wxZWdnB/aPHDlSAwcOVLdu3fTss89q27ZtgX3Dhg3TM888o/T0dI0dO1Zr1649q88hSW+++aZWr16tAQMGqLCwUJL/AUVhYaG6d+8eCPfR0dGaNm1aUD2S1Lp168DPl1xyiSQpJydHkrRx40alp6cHHZ+enq6NGzeesqbevXvLbrcHwnhmZqa6du0a6HJ/3DXXXBP4uVatWmratGng2mvWrFFmZmZQ/T169JBpmtqxY4fGjx8ftO/E/waS1LNnTxUUFOjrr7/WP//5z/Oq9V0iwAMAAAAIMW6XW06bU0Xe8ltUi73FctqccrvcVXrfJk2ayDCMSk9U980336hv37668cYb9d///lerVq3SmDFjVFJSEjjmiSee0Pr169WzZ0/Nnz9fLVq0CATZgQMHavv27brnnnu0bt06dejQQa+99lql6v7lGPVLLrlEqampqlWrVmBbQUGBJGnOnDlavXp14LVhw4agcfCSAt37pZ+74Jvm2Q1ZcDqd6tevnzIyMlRSUqL33nuv0gG6oKBAgwYNCqp/zZo12rJlixo3bqzBgwcH7atfv37Q+Q6HQ/fcc4/Gjh2rpUuXqm/fvmf1maoaAR4AAABASEmNS1XDuIY6eOxgmVZxy7J08NhBNYprpNS41Cq9b61atdSjRw+98cYb5U6KdrKlxJYsWaLk5GSNGTNGHTp0UJMmTZSVlVXmuLS0NI0YMUJffPGFbrnllqDx4ElJSRo8eLBmzpyphx56SFOnTq1w3XfddZfmzp2rVatWnfK4Fi1ayOVyKTs7W6mpqUGvpKSkCt+vefPmWrx4cdC2xYsXq0WLFoH3YWFh8vl8Zc4dOHCgvvzyS7355pvyer265ZZbyhxz4mSBubm52rx5s5o3by5JateunTZs2FCm/tTUVDmdTtWqVSto2y8np5P83egXLlyo3//+94qPj6/w5z4XWEYOAAAAQEixGTb9odkfNPG7idp1ZJfqRNSRy+FSsbdYB48dlNvl1l3N7pLNqPr2yjfeeEPp6em66qqr9NRTT6l169byer2aO3euJk+eXG438SZNmig7O1vvv/++rrzySs2ZMyfQui5Jx44d06hRo3TrrbeqYcOG2r17t5YvX64+ffpI8s94fsMNNygtLU25ublasGBBILBWxIgRIzRnzhz99re/1dixY3XttdcqPj5emzdv1qeffiq73S7JP9Heww8/rBEjRsg0Tf3qV7+Sx+PR4sWL5Xa7de+991bofqNGjdLtt9+utm3bqlu3bpo9e7ZmzpypL7/8MnBMSkqK5s2bp/T0dLlcrkBQbt68uTp27KhHHnlEAwYMUERERJnrP/XUU6pdu7bq1q2rMWPGqE6dOurdu7ck/2z/HTt21NChQzVw4EBFRUVpw4YNmjt3rl5//fUK1d+8eXMdPHhQkZGRJz1m37592rdvn7Zu9c+zsG7dOsXExKhBgwZBvRqqnIUgHo/HkmR5PJ6aLgUAAAC4YB07dszasGGDdezYsTO+xqr9q6xRC0dZt/7nVuumWTdZt/7nVusvC/9irdq/quoKLceePXusIUOGWMnJyZbT6bQuvfRS66abbrIWLFgQOEaSNWvWrMD7UaNGWbVr17aio6OtO+64w5o0aZIVGxtrWZZlFRcXW3feeaeVlJRkOZ1Oq379+tbQoUMD383QoUOtxo0bWy6Xy0pISLDuuece6+DBg5WquaioyHr22WetNm3aWBEREZbL5bKaNWtmjRgxwsrOzg4cZ5qm9fLLL1tNmza1wsLCrISEBKtHjx7WwoULLcuyrAULFliSrNzc3MA5q1atsiRZO3bsCGx78803rUaNGllhYWFWWlqaNW3atKB6Pv74Yys1NdVyOBxWcnJy0L5//OMfliRr2bJlQduP33v27NlWy5YtLafTaV111VXWmjVrgo5btmyZ1b17dys6OtqKioqyWrdubY0bN+6U309ycrI1adKkk+6PjY21MjIyAu/Hjh1rSSrzOvGYXzrV73xFc6hhWWcxE8MFKD8/X7GxsfJ4PHK7q3bMDAAAAAC/oqIi7dixQw0bNlR4ePmT0VWEaZnamrdV+cX5crvcSo1LrZaWd5w7Tz/9tD744IMyk/V99dVX6tq1q3Jzc0+5ZN/56lS/8xXNoXShBwAAABCybIZNafFpNV0GqkBBQYF27typ119/Xc8880xNl3Ne4tEUAAAAAKDGDR06VO3bt1eXLl3Ou+Xbzhe0wAMAAAAAalxmZqYyMzNPur9Lly5lVh242NACDwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAUMUMw9BHH31U02XgAnNBBfgnnnhChmEEvZo1a1bTZQEAAACoJpZpquiHzSpcvlxFP2yWZZrVfs99+/bpgQceUKNGjeRyuZSUlKRevXpp3rx51X7vM1VSUqIXXnhB7dq1U1RUlGJjY9WmTRs99thj2rNnzzmv53x7wJGSkiLDMPT++++X2deyZUsZhhFYo/7w4cN64IEH1LRpU0VERKhBgwYaNmyYPB5PtdfpqPY7nGMtW7bUl19+GXjvcFxwHxEAAACApMKVq5T77rsq3r5NVkmJDKdTrkaNFd+3ryLbta2We+7cuVPp6emKi4vTCy+8oFatWqm0tFSff/65hgwZok2bNlXLfc9GcXGxrrvuOq1du1ZPPvmk0tPTlZCQoB07dmj69Ol67bXXNGHChJous8YlJSUpIyNDd955Z2Dbt99+q3379ikqKiqwbc+ePdqzZ48mTpyoFi1aKCsrS4MHD9aePXv04YcfVmuNF1QLvOQP7PXq1Qu86tSpU9MlAQAAAKhihStXKef551W0YYPsMW6F1b9U9hi3ijZuVM7zz6tw5apque/9998vwzC0bNky9enTR2lpaWrZsqVGjhypb7/99qTnPfLII0pLS1NkZKQaNWqkxx9/XKWlpYH9a9asUdeuXRUTEyO326327dvru+++kyRlZWWpV69eio+PV1RUlFq2bKlPPvmkwjVPmjRJixYt0vz58zVs2DC1b99eDRo0UOfOnTVlyhSNHz8+cKxpmpowYYIaNmyoiIgItWnTJiiUfvXVVzIMQ/PmzVOHDh0UGRmpTp066Ycffgi65+TJk9W4cWM5nU41bdpU77zzTmBfSkqKJOnmm2+WYRhKSUnRzp07ZbPZAp/5uJdfflnJyckyTTNw7zlz5qh169YKDw9Xx44d9f333weds2jRIl177bWKiIhQUlKShg0bpqNHj572e+rbt68WLlyoXbt2Bbb985//VN++fYMahi+//HL9v//3/9SrVy81btxYv/nNbzRu3DjNnj1bXq/3tPc5GxdcgN+yZYvq16+vRo0aqW/fvsrOzj7l8cXFxcrPzw96AQAAADh/Waap3Hfflc/jUViDBrJFRsqw22WLjFRYUpJ8+fnKfe/dKu9Of/jwYX322WcaMmRIUIvscXFxcSc9NyYmRpmZmdqwYYNeeeUVTZ06VZMmTQrs79u3ry677DItX75cK1as0OjRoxUWFiZJGjJkiIqLi/X1119r3bp1eu655xQdHV3huqdPn67u3burbdvyeyUYhhH4ecKECZo2bZqmTJmi9evXa8SIEbr77ru1cOHCoHPGjBmjF198Ud99950cDocGDBgQ2Ddr1iw9+OCDeuihh/T9999r0KBBuu+++7RgwQJJ0vLlyyVJGRkZ2rt3r5YvX66UlBR169ZNGRkZQffJyMhQ//79ZbP9HF1HjRqlF198UcuXL1dCQoJ69eoVeBiybds2XX/99erTp4/Wrl2rGTNmaNGiRRo6dOhpv6e6deuqR48eevvttyVJhYWFmjFjRtBnOxmPxyO32139PcCtC8gnn3xi/fvf/7bWrFljffbZZ9Y111xjNWjQwMrPzz/pOWPHjrUklXl5PJ5zWDkAAABwcTl27Ji1YcMG69ixY5U/d9MP1rbeva2d9/SzsgcNLvPaefc91rbeva1jm36o0pqXLl1qSbJmzpx52mMlWbNmzTrp/hdeeMFq37594H1MTIyVmZlZ7rGtWrWynnjiiUrXe1x4eLg1bNiwoG29e/e2oqKirKioKOuaa66xLMuyioqKrMjISGvJkiVBx/7P//yPddddd1mWZVkLFiywJFlffvllYP+cOXMsSYH/lp06dbL++Mc/Bl3jtttus2688cbA+/K+nxkzZljx8fFWUVGRZVmWtWLFCsswDGvHjh1B937//fcD5xw6dMiKiIiwZsyYEaj1T3/6U9B1/+///s+y2Wyn/F1LTk62Jk2aZH300UdW48aNLdM0rbfffttq27atZVmWFRsba2VkZJR77oEDB6wGDRpYf/3rX096fcs69e+8x+OpUA69oFrgb7jhBt12221q3bq1evTooU8++UR5eXn697//fdJzHn30UXk8nsDrxO4SAAAAAM4/Zr7HP+bd5Sp3vxEeLqukRGZ+1U4qZlnWGZ87Y8YMpaenq169eoqOjtZjjz0W1Ft45MiRGjhwoLp166Znn31W27ZtC+wbNmyYnnnmGaWnp2vs2LFau3btWX0OSXrzzTe1evVqDRgwQIWFhZKkrVu3qrCwUN27d1d0dHTgNW3atKB6JKl169aBny+55BJJUk5OjiRp48aNSk9PDzo+PT1dGzduPGVNvXv3lt1u16xZsyRJmZmZ6tq1a6DL/XHXXHNN4OdatWqpadOmgWuvWbNGmZmZQfX36NFDpmlqx44dGj9+fNC+X/bY7tmzpwoKCvT111/rn//852lb3/Pz89WzZ0+1aNFCTzzxxCmPrQoXVID/pbi4OKWlpWnr1q0nPcblcsntdge9AAAAAJy/bO5YGU6nrOLicvdbRUUynE7Z3LFVet8mTZrIMIxKT1T3zTffqG/fvrrxxhv13//+V6tWrdKYMWNUUlISOOaJJ57Q+vXr1bNnT82fP18tWrQIBNmBAwdq+/btuueee7Ru3Tp16NBBr732WqXq/uUY9UsuuUSpqamqVatWYFtBQYEkac6cOVq9enXgtWHDhjKTsx3v3i/93AXfPMshC06nU/369VNGRoZKSkr03nvvVaj7+okKCgo0aNCgoPrXrFmjLVu2qHHjxho8eHDQvvr16wed73A4dM8992js2LFaunSp+vbte9J7HTlyRNdff71iYmI0a9asoO+kulzQAb6goEDbtm0LPBECAAAAEPpcTVLlatRY3oMHy7SKW5Yl76FDcjVuLFeT1Cq9b61atdSjRw+98cYb5U6KlpeXV+55S5YsUXJyssaMGaMOHTqoSZMmysrKKnNcWlqaRowYoS+++EK33HJL0HjwpKQkDR48WDNnztRDDz2kqVOnVrjuu+66S3PnztWqVaee2K9FixZyuVzKzs5Wampq0CspKanC92vevLkWL14ctG3x4sVq0aJF4H1YWJh8Pl+ZcwcOHKgvv/xSb775prxer2655ZYyx5w4WWBubq42b96s5s2bS5LatWunDRs2lKk/NTVVTqdTtWrVCtpW3pj1AQMGaOHChfr973+v+Pj4cj9jfn6+rrvuOjmdTn388ccKDw+v2Jdzli6oNdYefvhh9erVS8nJydqzZ4/Gjh0ru92uu+66q6ZLAwAAAFBFDJtN8X37Kuf551W6a5cctWv7u80XFcl76JDsbrfi/9BXhq3q2yvfeOMNpaen66qrrtJTTz2l1q1by+v1au7cuZo8eXK53cSbNGmi7Oxsvf/++7ryyis1Z86cQOu6JB07dkyjRo3SrbfeqoYNG2r37t1avny5+vTpI0kaPny4brjhBqWlpSk3N1cLFiwIBNaKGDFihObMmaPf/va3Gjt2rK699lrFx8dr8+bN+vTTT2W32yX5J9p7+OGHNWLECJmmqV/96lfyeDxavHix3G637r333grdb9SoUbr99tvVtm1bdevWTbNnz9bMmTODlvtOSUnRvHnzlJ6eLpfLFQjKzZs3V8eOHfXII49owIABioiIKHP9p556SrVr11bdunU1ZswY1alTR71795bkn+2/Y8eOGjp0qAYOHKioqCht2LBBc+fO1euvv16h+ps3b66DBw8qMjKy3P3Hw3thYaH+9a9/BU2GnpCQEPg+q8UpR8iHmDvuuMO65JJLLKfTaV166aXWHXfcYW3durVS16jo5AEAAAAAztzZTGJ33NEVK63dIx+ytvXubW298UZrW+/e1u6HHrKOrlhZhZWWtWfPHmvIkCFWcnJyIHvcdNNN1oIFCwLH6BeTtI0aNcqqXbu2FR0dbd1xxx3WpEmTrNjYWMuyLKu4uNi68847raSkJMvpdFr169e3hg4dGvhuhg4dajVu3NhyuVxWQkKCdc8991gHDx6sVM1FRUXWs88+a7Vp08aKiIiwXC6X1axZM2vEiBFWdnZ24DjTNK2XX37Zatq0qRUWFmYlJCRYPXr0sBYuXGhZ1s8TyeXm5gbOWbVqlSUpMNmcZVnWm2++aTVq1MgKCwuz0tLSrGnTpgXV8/HHH1upqamWw+GwkpOTg/b94x//sCRZy5YtC9p+/N6zZ8+2WrZsaTmdTuuqq66y1qxZE3TcsmXLrO7du1vR0dFWVFSU1bp1a2vcuHGn/H6OT2J3MidOYne8jvJeJ34Hv1QVk9gZlnUWMzFcgPLz8xUbGxtYBgAAAABA1SsqKtKOHTvUsGHDs+p+bJmmirdslZnvkc0dK1eT1Gppece58/TTT+uDDz4oM1nfV199pa5duyo3N/eUS/adr071O1/RHHpBdaEHAAAAcHExbDaFN02r6TJQBQoKCrRz5069/vrreuaZZ2q6nPMSj6YAAAAAADVu6NChat++vbp06VLp2ecvFrTAAwAAAABqXGZmpjIzM0+6v0uXLmVWHbjY0AIPAAAAAEAIIMADAAAAqDEXe4sqLh5V8btOgAcAAABwzoWFhUmSCgsLa7gS4Nw4/rt+/Hf/TDAGHgAAAMA5Z7fbFRcXp5ycHElSZGSkDMOo4aqAqmdZlgoLC5WTk6O4uDjZ7fYzvhYBHgAAAECNqFevniQFQjxwIYuLiwv8zp8pAjwAAACAGmEYhi655BIlJiaqtLS0pssBqk1YWNhZtbwfR4AHAAAAUKPsdnuVhBvgQsckdgAAAAAAhAACPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAAIQAAjwAAAAAACGAAA8AAAAAQAggwAMAAAAAEAII8AAAAAAAhAACPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAAIQAAjwAAAAAACGAAA8AAAAAQAggwAMAAAAAEAII8AAAAAAAhAACPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAAIQAAjwAAAAAACGAAA8AAAAAQAggwAMAAAAAEAII8AAAAAAAhAACPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIcNR0AQAAAAAAmJaprXlblV+cL7fLrdS4VNkM2pxPRIAHAAAAANSo1Tmr9d6m97Qjb4dKzBI5bU41jGuoPzT7g65IvKKmyztv8DgDAAAAAFBjVues1sTvJmrjoY2Kccbo0uhLFeOM0aZDmzTxu4lanbO6pks8bxDgAQAAAAA1wmt69dbat7T/6H7VCq+liLAI2QybIsMilRSTpPzifE3fNF2mZdZ0qecFutADAAAAAE6rqseor85ZrbfWvqXle5fLMAwdKT2iSEekLo2+VLGuWBmGoToRdbQ9b7u25m1VWnzaSWtpENNAMzbN0IbDG+QOc6tXai+57C4dKTlyQY2nJ8ADAAAAAE6pqseoH+82v//ofhmGoQhHhEzLVEFpgbZ7tqtRbCPFumLlcrh0qOiQ8ovzT1pLblGu8orzZMkKHPP+5vcVZgtTQkSC3E73BTOePvQfQQAAAAAAqk1Vj1E3LVPvbXpPnmKPLo2+VHabXaZlym6zK8IRoVKzVHsK9siSpWJvsZw2p9wut7ymV1PXTtUjXz+i7/Z9pyhHlIq9xcotzg0K78eVmqXaf3S/JF0w4+lpgQcAAAAAlOvEsN0gpoEMw5Ak/xh1R5J2Hdml6Zumq3VC6wp3Ud+at1U78nYoISJBEY4IRToiVVBaoHAjXIZhyGlz6qj3qApKCpRblKvmtZtr1f5VGjpvqPYf3S9TpgwZ8hR7VGKWnPJePvm07+g+tUpopd1Hdle61vNNaFYNAAAAAKh2J4bt4+H9uF+OUa+o/OJ8lZglCnf4A/ul0ZfKYXOoyFckn+mTYRjymT7tPbpXbpdbiZGJemnFSzpQeECWLNlll02204b34zwlHhV6C8+o1vMNAR4AAAAAUK4Tw3Z5XA6XSsySoDHqp+N2ueW0OVXkLZIkxbpi1Ti2saLDouW1vCryFsmyLKXGpWp4u+H6fOfn/hrs/sBvs9lks1U8ylqydKTkyBnVer4hwAMAAAAAyvXLsP1LJ45Rr6jUuFQ1jGuog8cOyrL8Y9djXbFqXqu5msU3U5wrTldecqVe/c2ryi3O1eFjh+W0OWXKlGVZMk3/n4aM09zpZyW+kjOq9XxDgAcAAAAAlKu8sH2cZVk6eOygGsU1UmpcaoWvaTNs+kOzP8jtcmvXkV0qLC2Uz/LpmPeYDhcdVt2ouhrUepAcNodW7V+lErNEhd5CFXoLZcmSTz55LW+lPkeYLeyMaj3fEOABAAAAAOU6WdguLC3UriO75Ha5dVezuyo9KdwViVfo4Q4Pq1ntZjpSckR7CvboSMkRNa/dXA93eFhXJF6h1Tmr9fWPX5c7w7ykk24vT2Fp4RnXej6p9Cz0pmmWO97ANE3t3r1bDRo0qJLCAAAAAAA173jYPr72+qGiQ3LanGpeu7nuanbXGa+tfkXiFWqd0Fpb87YqvzhfbpdbqXGpshm2wOz3ps+UTTaZMiUp0G2+MuHdkKEkd5KGXDEk5NeBr3CAz8/P18CBAzV79my53W4NGjRIY8eOld1ulyQdOHBADRs2lM/nq7ZiAQAAAADn3qnC9tmwGTalxaeV2X589nu3y639x/YHZpy3VHbs+4kBvzyxrljFu+LVOqH1WdV6PqhwgH/88ce1Zs0avfPOO8rLy9MzzzyjlStXaubMmXI6nZJUZkwEAAAAAODCcLKwXR2Oz34fHRYth80hh+FfZs6UGdT6Hm4Ll9fyymE4ZFn+8fHHdxuGIbfTrcZxjbXDs0Nb87aes/qrS4UD/EcffaS3335bXbp0kST17t1bPXv2VK9evfTxxx9LUpl1AQEAAAAAFy/LNFW8ZavMfI9s7li5mqTKqMAScMdnvz++LrzD5lC4I1wlZolM6+fu9ImRifqx4EeZlqlIR6RkSD7LJ5/pU5gtTMnuZIU7wnW46HBILx93XIUD/IEDB5ScnBx4X6dOHX355Zfq0aOHbrzxRv3v//5vtRQIAAAAAAg9hStXKffdd1W8fZuskhIZTqdcjRorvm9fRbZre8pzj89+v/HgRkU6IlVQWqBwe7icdn/v72PeY4pyREmSmtdurm2521RqlcqwjEDLe/3o+op1xaqwtDDkl487rsIDFho0aKCNGzcGbYuJidEXX3yhY8eO6eabb67y4gAAAAAAoadw5SrlPP+8ijZskD3GrbD6l8oe41bRxo3Kef55Fa5cdcrzj89+HxseK4fhkE02FfmKVOIrUWFpoWyGTQ67Q26XWyPbj9S1l12rWuG1lBqXqma1mqlZ7WaKdcWe8VJ356sKB/jrrrtOGRkZZbZHR0fr888/V3h4eJUWBgAAAAAIPZZpKvfdd+XzeBTWoIFskZEy7HbZIiMVlpQkX36+ct97V5Z58onnpJ9nv7+i7hWqHVFbNsOmUl+p7Da7aofXVtvEtnq4w8NqV7ed/tD8D6oTUUdHSo74J7WzzLNe6u58ZFgVnHkuNzdXe/bsUcuWLcvdf+TIEa1cuVKdO3eu0gLPtfz8fMXGxsrj8cjtDv0uFgAAAABwLhX9sFl7Rj8ie4xbtsjIMvvNo0flKzii+s8+p/Cmp59UzrRMbc3bqryiPHlKPIpzxSnWFVtmFvzVOasDS92VmCVy2pxqFNforJa6O1cqmkMrPAY+Pj5e8fHxJ90fExMT8uEdAAAAAHB2zHyPf8y7yxXYZsmSebRQKi2VZbfLKi6Rme+p0PUqOvt9dS11dz6pcIAHAAAAAOB0bO5YGU6nrOJiGZGR8nk8Kv3xR5mFR2WZliRLhiNMJT/uUeSVVXzvc7jUXU24cB5FAAAAAABqnKtJqlyNGst78KC8eXkq3rZNviNHJEeYv1XetGT5fMqdPj0wmZ1lmir6YbMKly9X0Q+bTzs+/mJFCzwAAAAAoMoYNpvi+/bV/ueeU8mWLTK9Xv9YeMuSVVQkw+mUs1EjmSdMZpc3ffoZLTd3sanwJHYXCyaxAwAAAICzl/fRf7R//DhZXp8kyTAMGVFRcl56qeyxsTKPHlVpTo5s4eGySkrkSEiQ4XLJKi6W9+BB2d1uJf7lLxdFiK/ySeyOs9vt2rt3rxITE4O2Hzp0SImJifL5fJWvFgAAAABwQXFeWl/2OnXkiIuXTFNyOGSLipJhGP4Dwl3yHTwoMzpazssuk1VSIss0ZYuKUlhSkkp37VLue+8q4oo2Mmw2Waap4i1bZeZ7ZHPHytUkVYbt4hoVXukAf7IG++LiYjmdzrMuCAAAAAAQ+mzuWNlcLhkOh4zwcJX++KO8e/fKCA9X2KWXypebJ7OkRLaiIhVv2iTLsoJa6R21a6t42zZ/aD96VLnvvnvRd7OvcIB/9dVXJfm7Pfzv//6voqOjA/t8Pp++/vprNWvWrOorBAAAAACEnLCGKTIiInVszRpZxcVB+0q2b/dPaOfzBZacM2w2yTRlHjmi4m3b5GzYUFZJiQq/+075s2fL5/EEdbMv2rhROc8/f9F0s5cqEeAnTZokyd8CP2XKFNnt9sA+p9OplJQUTZkypeorBAAAAACElEPvTdfBV1+VmZdX/gE/TWgnm01yOmUcz5d2uxQRIevYMZXu2iVbQh0VLFwon8ejsAYNAt3vjcjIcrvZX+gqHOB37NghSeratatmzpyp+Pj4aisKAAAAABCa9j3/gnIzM/3j3k/HNKWSEn9wPx7ODUNyOuUrKJCzYYq8OTn+lvfjY+d/YhhGUDf78KYX7vrvx1X6EcWCBQsI7wAAAACAMgqWLVPu229XLLwfZ5oyi4pkeb3+lnmvV2ZJiQzDUHjLy2WV+rvYl8f4aQZ7M99TRZ/g/FbpSex8Pp8yMzM1b9485eTkyPzFf5j58+dXWXEAAAAAgNBw9LsV2vPgcKmSK5PZ3G4ZhiGz8KjM0lIZNkP2iAjZYmIU2b69Cpcvk1VcLCMyssy5x9eVt7ljq+hTnN8qHeAffPBBZWZmqmfPnrr88svLdGMAAAAAAFxcCleu0v6nn5YvP7/S51qmqfBWl8s8WiiVlspyOGQeOqTwli0U/dvf6MgXX6ho40aFJSUF5U/LsuQ9dEjhLZrL1SS1Kj/OeavSAf7999/Xv//9b914443VUQ+AM2Ga0oGN0rE8KSJOSmjunxAEAAAAqGaWaSr33Xfl83j8Y9kr2QJv5uXJPFooW3i4LEm+Q4dkj41V/B/6yuZwKL5vX+U8/7xKd+2So3Ztf7f5oiJ5Dx2S3e1W/B/6XhQT2ElnMAbe6XQqNfX8frrxxhtvKCUlReHh4br66qu1bNmymi4JqD7ZS6WZf5RmDZL+O9z/58w/+rcDAAAAVcAyTRX9sFmFy5er6IfNsk4YSl28ZauKt2+To04dGWFhlbuwzSZZlrx79qh0z4/yFRxReIvmQUvDRbZrq8S//EXhzZvLV3DkpMddDCrdAv/QQw/plVde0euvv35edp+fMWOGRo4cqSlTpujqq6/Wyy+/rB49euiHH35QYmJiTZcHVK3spdIXY/wt7zF1JUeE5D0m7V3r337dOKnB1TVdJQAAAEJY4cpVyn33XRVv3+Zfs93plKtRY8X37avIdm1l5ntklZTIfkkd2aKi5CspkUpLK3RtIzJSVlGRYm68QTG//rVs7li5mqSWaVGPbNdWEVe0UfGWrTLzPSc97kJnWJZlVeaEm2++WQsWLFCtWrXUsmVLhf3iCcvMmTOrtMDKuvrqq3XllVfq9ddflySZpqmkpCQ98MADGj169GnPz8/PV2xsrDwej9xud3WXC5w50/S3tO9dI9VqFFh2Q5JkWdLhHVL9NtLNfw+57vRer6m5m/Zrn6dI9WLD1b1ZXTkcofUZAAAALgSFK1cp5/nn5fN4/Eu5uVyyiovlPXhQdrdbiX/5i2xRUdoz+hHZY9yySktVvG2bzMJCyes9/Q3Cw2VYluo//7zcPa6r/g90nqpoDq10C3xcXJxuvvnmsyquupSUlGjFihV69NFHA9tsNpu6deumb775ptxziouLVVxcHHiffwaTLgA14sBG6eAP/pb3X/aGMQwpJlE6sMl/XN2WNVPjGXh3aZbeXLBVBwtKZFqWbIahOtFO3d81VX2vTq7p8gAAAC4aJ45tD2vQINAD24iMVFhSkkp37VLue+/qkmeflatR48BEc67GjVXy4275Dh0ufzy8YfgbnCSpuFi22rUU/dvfnMNPFroqHeAzMjKqo44qcfDgQfl8PtWtWzdoe926dbVp06Zyz5kwYYKefPLJc1EeULWO5UneYn+3+fI4IiRvjv+4EPHu0iyNm7NRpT5T4Q67wuyGSn2Wco4Ua9ycjZJEiAcAADhHAmPbExLKDJ82DEOO2rVVvG2bSrZtLzPRnCutqUp//FGlu3aVbYn/RSdwR71LLrqu8GfqjL4lr9erL7/8Um+99ZaOHDkiSdqzZ48KCgqqtLhz4dFHH5XH4wm8du3aVdMlARUTESc5XP4x7+XxHvPvj4g7l1WdMa/X1JsLtqrUZyrG5ZDLYZPNMORy2BTjcqjU59/v9ZqnvxgAAADO2vGx7YbLVe5+IzxcVkmJzHxPmYnmvHv3yBbuUnjLlv7128N+0XZsGDJcLoU1aCD5vCresvUcfKLQV+kW+KysLF1//fXKzs5WcXGxunfvrpiYGD333HMqLi7WlClTqqPOCqlTp47sdrv2798ftH3//v2qV69euee4XC65TvILCZzXEppLdZr6J6yrFVV2DPyRHP8Y+ITmNVdjJczdtF8HC0oU7rDL9osnvDbDULjDroMFJZq7ab9uuPySGqoSAADg4mFzx8pwOmUVF/tD+C9YRUUynE7Z3LGSyp9ozufJ074nnpQtPl6Wt1RWwdFAeLfXqS3DtFS650eZ+Z5z/fFCUqVb4B988EF16NBBubm5ioj4uevuzTffrHnz5lVpcZXldDrVvn37oDpM09S8efN0zTXX1GBlQDWw2aSr/iRFxPonrCspkEyf/8/DO/wt71f+MWQmsNvnKZJpWQqzl7+6RZjdkGlZ2ucpOseVAQAAXJxcTVLlatRY3oMH9cu5zy3LkvfQIbkaN5aryc/LjBs2m8KbpinyyisV3jRN9tg4GS6nbHa7wuJryZmUJOdllyksIUE2w1bmIQBOrdL/sv+///s/PfbYY3I6nUHbU1JS9OOPP1ZZYWdq5MiRmjp1qt5++21t3LhRf/7zn3X06FHdd999NV0aUPUaXO1fKu6S1lKRR8rL8v9Zv4103TMhtYRcvdhw2Qz/mPfylPr8E9rViw0/x5UBAABcnAybTfF9+8rudqt01y6ZR4/K8vlkHj2q0l27ZHe7Ff+Hvqccv34mDwFwcpXuQm+apnzlzCS4e/duxcTEVElRZ+OOO+7QgQMH9Le//U379u3TFVdcoc8++6zMxHbABaPB1dJlV/pnmz+W5295T2geMi3vx3VvVld1op3KOVKsMLsR1I3etCwVeX1KjHGpezP+vwwAAHCuHB/bHlgH/vAhGU6nwls0V/wf/OvAn8rxhwAnTnBnhIfLKiqS99ChCj0EwM8qvQ78HXfcodjYWP39739XTEyM1q5dq4SEBP3+979XgwYNzutZ6iuCdeCBmnOyWeiLvD457Tb9tWdzZqEHAACoAZZpBo1tdzVJrVToLly56ueHACUlMpxOuRo3rtBDgItBRXNopQP87t271aNHD1mWpS1btqhDhw7asmWL6tSpo6+//lqJiYlnXXxNIsADNYt14AEAAC5MZ/sQ4EJWbQFe8i8j9/7772vt2rUqKChQu3bt1Ldv36BJ7UIVAR6oeV6vqbmb9mufp0j1YsPVvVldORz85Q4AAIALU7UG+AsZAR4AAAAAcC5VNIdWehI7SdqyZYsWLFignJwcmaYZtO9vf/vbmVwSAAAAAACcQqUD/NSpU/XnP/9ZderUUb169WScMFO0YRgEeAAAAAAAqkGlA/wzzzyjcePG6ZFHHqmOegAAAAAAQDkqPStUbm6ubrvttuqoBQAAAAAAnESlA/xtt92mL774ojpqAQAAAAAAJ1HpLvSpqal6/PHH9e2336pVq1YKCwsL2j9s2LAqKw4AAAAAAPhVehm5hg0bnvxihqHt27efdVE1iWXkAAAAAADnUrUtI7djx46zKgwAAAAAAFRepcfAn8iyLFWyAR8AAAAAAJyBMwrw06ZNU6tWrRQREaGIiAi1bt1a77zzTlXXBgAAAAAAflLpLvQvvfSSHn/8cQ0dOlTp6emSpEWLFmnw4ME6ePCgRowYUeVFAgAAAABwsTujSeyefPJJ9evXL2j722+/rSeeeCLkx8gziR0AAAAA4FyqaA6tdBf6vXv3qlOnTmW2d+rUSXv37q3s5QAAAAAAQAVUOsCnpqbq3//+d5ntM2bMUJMmTaqkKAAAAAAAEKzSY+CffPJJ3XHHHfr6668DY+AXL16sefPmlRvsAQAAAADA2at0C3yfPn20dOlS1alTRx999JE++ugj1alTR8uWLdPNN99cHTUCAAAAAHDRq/Qkdhc6JrEDAAAAAJxLFc2hle5CL0k+n0+zZs3Sxo0bJUktWrTQ73//ezkcZ3Q5AAAAAABwGpVO3OvXr9dNN92kffv2qWnTppKk5557TgkJCZo9e7Yuv/zyKi8SAAAAAICLXaXHwA8cOFAtW7bU7t27tXLlSq1cuVK7du1S69at9ac//ak6agQAAAAA4KJX6Rb41atX67vvvlN8fHxgW3x8vMaNG6crr7yySosDAAAAAAB+lW6BT0tL0/79+8tsz8nJUWpqapUUBQAAAAAAglU6wE+YMEHDhg3Thx9+qN27d2v37t368MMPNXz4cD333HPKz88PvAAAAAAAQNWo9DJyNtvPmd8wDEnS8Uuc+N4wDPl8vqqq85xhGTkAAAAAwLlUbcvILViw4KwKAwAAAAAAlVfpAN+5c+fqqAMAAAAAAJxCpQO8JBUVFWnt2rXKycmRaZpB+2666aYqKQwAAAAAAPys0gH+s88+U79+/XTw4MEy+0J13DsAAAAAAOe7Ss9C/8ADD+i2227T3r17ZZpm0IvwDgAAAABA9ah0gN+/f79GjhypunXrVkc9AAAAAACgHJUO8Lfeequ++uqraigFAAAAAACcTKXXgS8sLNRtt92mhIQEtWrVSmFhYUH7hw0bVqUFnmusAw8AAAAAOJeqbR346dOn64svvlB4eLi++uorGYYR2GcYRsgHeAAAAAAAzkeVDvBjxozRk08+qdGjR8tmq3QPfAAAAAAAcAYqncBLSkp0xx13EN4BAAAAADiHKp3C7733Xs2YMaM6agEAAAAAACdR6S70Pp9Pzz//vD7//HO1bt26zCR2L730UpUVBwAAAAAA/Cod4NetW6e2bdtKkr7//vugfSdOaAcAAAAAAKpOpQP8ggULqqMOAAAAAABwCmc1E93u3bu1e/fuqqoFAAAAAACcRKUDvGmaeuqppxQbG6vk5GQlJycrLi5OTz/9tEzTrI4aAQAAAAC46J3ROvD/+Mc/9Oyzzyo9PV2StGjRIj3xxBMqKirSuHHjqrxIAAAAAAAudoZlWVZlTqhfv76mTJmim266KWj7f/7zH91///368ccfq7TAcy0/P1+xsbHyeDxyu901XQ4AAAAA4AJX0Rxa6S70hw8fVrNmzcpsb9asmQ4fPlzZywEAAAAAgAqodIBv06aNXn/99TLbX3/9dbVp06ZKigIAAAAAAMEqPQb++eefV8+ePfXll1/qmmuukSR988032rVrlz755JMqLxAAAAAAAJxBC3znzp21efNm3XzzzcrLy1NeXp5uueUW/fDDD7r22muro0YAAAAAAC56lZ7E7kLHJHYAAAAAgHOpyiex27Jli+666y7l5+eX2efxePSHP/xB27dvP7NqAQAAAADAKVU4wL/wwgtKSkoq92lAbGyskpKS9MILL1RpcQAAAAAAwK/CAX7hwoW67bbbTrr/9ttv1/z586ukKAAAAAAAEKzCAT47O1uJiYkn3V+nTh3t2rWrSooCAAAAAADBKhzgY2NjtW3btpPu37p1K5O+AQAAAABQTSoc4H/961/rtddeO+n+V199lWXkAAAAAACoJhUO8I8++qg+/fRT3XrrrVq2bJk8Ho88Ho+WLl2qPn366PPPP9ejjz5anbUCAAAAAHDRclT0wLZt2+rDDz/UgAEDNGvWrKB9tWvX1r///W+1a9euygsEAAAAAACVCPCS9Lvf/U5ZWVn67LPPtHXrVlmWpbS0NF133XWKjIysrhoBAAAAALjoVSrAS1JERIRuvvnm6qgFAAAAAACcRIXHwAMAAAAAgJpDgAcAAAAAIAQQ4AEAAAAACAEEeAAAAAAAQkCFJrHLz8+v8AXdbvcZFwMAAAAAAMpXoQAfFxcnwzBOeYxlWTIMQz6fr0oKAwAAAAAAP6tQgF+wYEF11wEAAAAAAE6hQgG+c+fO1V0HAAAAAAA4hQoF+PIUFhYqOztbJSUlQdtbt2591kUBAAAAAIBglQ7wBw4c0H333adPP/203P2MgQcuDKZpaXPOEXkKSxUbGaa0xBjZbKeeCwMAAABA9al0gB8+fLjy8vK0dOlSdenSRbNmzdL+/fv1zDPP6MUXX6yOGgGcYyuyDuvtJVnamlOgEq9PToddqYnRurdTston16rp8gAAAICLUqUD/Pz58/Wf//xHHTp0kM1mU3Jysrp37y63260JEyaoZ8+e1VEngHNkRdZhjZuzUXmFpUqMcSk8zKWiUp/W7/Fo3JyNGtOzOSEeAAAAqAG2yp5w9OhRJSYmSpLi4+N14MABSVKrVq20cuXKqq0OwDllmpbeXpKlvMJSpdSOVJTLIbvNUJTLoeRakfIcK9W0JVkyTatK7+v1mvr0+73KWLxDn36/V16vWaXXBwAAAC4ElW6Bb9q0qX744QelpKSoTZs2euutt5SSkqIpU6bokksuqY4aAZwjm3OOaGtOgRJjXDKM4PHuhmEoIdqlLTkF2pxzRM3quavknu8uzdKbC7bqYEGJTMuSzTBUJ9qp+7umqu/VyVVyDwAAAOBCUOkA/+CDD2rv3r2SpLFjx+r666/Xu+++K6fTqczMzKquD8A55CksVYnXp/AwV7n7w8PsOlhQLE9haZXc792lWRo3Z6NKfabCHXaF2Q2V+izlHCnWuDkbJYkQDwAAAPyk0gH+7rvvDvzcvn17ZWVladOmTWrQoIHq1KlTpcUBOLdiI8PkdNhVVOpTlKvsXw9Fpf4J7WIjw876Xl6vqTcXbFWpz1SMyyHbTy3+LoehMLuhI8Vevblgq+5onySHo9KjfQAAAIALzln9q9iyLEVERKhdu3aEd+ACkJYYo9TEaB0oKJZlBY9ztyxLBwqK1SQxWmmJMWd9r7mb9utgQYnCHfZAeD/OZhgKd9h1sKBEczftP+t7AQAAABeCMwrw//jHP3T55ZcrPDxc4eHhuvzyy/W///u/VV0bgHPMZjN0b6dkxUaEKetwoY4We+UzLR0t9irrcKFiI8LUr1NylawHv89TJNOyFGYv/1phdkOmZWmfp+is7wUAAABcCCrdhf5vf/ubXnrpJT3wwAO65pprJEnffPONRowYoezsbD311FNVXiSAc6d9ci2N6dk8sA78wYJiOR12XV4/Vv2qcB34erHhshn+Me8uR9kQX+rzT2hXLza8Su4HAAAAhDrD+mU/2dNISEjQq6++qrvuuito+/Tp0/XAAw/o4MGDVVrguZafn6/Y2Fh5PB653VUzyzYQikzT0uacI/IUlio2MkxpiTFV0vJ+nNdrqvPEBco5Uhw0Bl6STMvSkWKvEmNcWvhwV8bAAwAA4IJW0Rxa6X8Vl5aWqkOHDmW2t2/fXl6vt7KXA3CestkMNavn1tWNaqtZPXeVhndJcjhsur9rqsLsNh0p9qrYa8q0LBV7TR0p9spp9+8nvAMAAAB+lf6X8T333KPJkyeX2f73v/9dffv2rZKiAFwc+l6drDE9mysxxqUSnz+4l/hMJca49NeezVlCDgAAADhBpbvQP/DAA5o2bZqSkpLUsWNHSdLSpUuVnZ2tfv36KSzs5+WlXnrppaqt9hygCz1w7nm9puZu2q99niLViw1X92Z1aXkHAADARaOiObTSAb5r164VOs4wDM2fP78ylz4vEOCB6lXdY+sBAACAUFPRHFrpWegXLFhwVoUBuHityDocmN2+xOuT02FXamK07q3C2e0BAACACxV9VAGcEyuyDmvcnI36/keP3OEOXRYfKXe4Q+v3eDRuzkatyDpc0yUCAAAA57UKtcDfcsstyszMlNvt1i233HLKY2fOnFklhQG4cJimpbeXZCmvsFQptSNl/LRkXJTLoUinXVmHCzVtSZbaJsXTnR4AAAA4iQq1wMfGxgb+wR0bG3vKV01KSUmRYRhBr2effbZGawIgbc45oq05BUqMcQX+LjnOMAwlRLu0JadAm3OO1FCFAAAAwPmvQi3wGRkZ5f58Pnrqqaf0xz/+MfA+JiamBqsBIEmewlKVeH0KD3OVuz88zK6DBcXyFJae48oAAACA0FHpSex27Nghr9erJk2aBG3fsmWLwsLClJKSUlW1nZGYmBjVq1evRmsAECw2MkxOh11FpT5Fucr+tVNU6p/QLjYyrJyzAQAAAEhnMIld//79tWTJkjLbly5dqv79+1dFTWfl2WefVe3atdW2bVu98MIL8nq9pzy+uLhY+fn5QS8AVSstMUapidE6UFCsX65caVmWDhQUq0litNIS6TEDAAAAnEylA/yqVauUnp5eZnvHjh21evXqqqjpjA0bNkzvv/++FixYoEGDBmn8+PH6y1/+cspzJkyYEDSGPykp6RxVC1w8bDZD93ZKVmxEmLIOF+posVc+09LRYq+yDhcqNiJM/TolM4EdAAAAcAqG9cvmsNOIjY3VV199pbZt2wZtX7Fihbp06aIjR6p2EqrRo0frueeeO+UxGzduVLNmzcps/+c//6lBgwapoKBALlf5Y2+Li4tVXFwceJ+fn6+kpCR5PB653e6zKx5AkPLWgW+SGK1+rAMPAACAi1h+fr5iY2NPm0MrHeB79eqliIgITZ8+XXa7XZLk8/l0xx136OjRo/r000/PrvJfOHDggA4dOnTKYxo1aiSn01lm+/r163X55Zdr06ZNatq0aYXuV9EvDsCZMU1Lm3OOyFNYqtjIMKUlxtDyDgAAgItaRXNopSexe+655/TrX/9aTZs21bXXXitJ+r//+z/l5+dr/vz5Z17xSSQkJCghIeGMzl29erVsNpsSExOruCoAZ8pmM9SsHg/HAAAAgMqqdIBv0aKF1q5dq9dff11r1qxRRESE+vXrp6FDh6pWrZrrAvvNN99o6dKl6tq1q2JiYvTNN99oxIgRuvvuuxUfH19jdQEAAAAAUBUq3YX+fLVy5Urdf//92rRpk4qLi9WwYUPdc889Gjly5EnHv5eHLvQAAAAAgHOp2rrQS1JeXp6WLVumnJwcmaYZtK9fv35ncsmz1q5dO3377bc1cm8AAAAAAKpbpQP87Nmz1bdvXxUUFMjtdsswfp58yjCMGgvwAAAAAABcyCq9DvxDDz2kAQMGqKCgQHl5ecrNzQ28Dh8+XB01AgAAAABw0at0C/yPP/6oYcOGKTIysjrqAXAeYKk3AAAA4PxT6QDfo0cPfffdd2rUqFF11AOghq3IOqy3l2Rpa06BSrw+OR12pSZG695OyWqfXHMrTQAAAAAXu0oH+J49e2rUqFHasGGDWrVqpbCwsKD9N910U5UVB+DcWpF1WOPmbFReYakSY1wKD3OpqNSn9Xs8Gjdno8b0bE6IBwAAAGpIpZeRs9lOPmzeMAz5fL6zLqomsYwcLlamaWn4jNX6/kePUmpHBk1QaVmWsg4X6vL6sZp0xxV0pwcAAACqUEVzaKUnsTNN86SvUA/vwMVsc84Rbc0pUGKMKyi8S/6HcwnRLm3JKdDmnCM1VCEAAABwcat0gAdwYfIUlqrE61N4mL3c/eFhdpV4ffIUlp7jygAAAABIFRwD/+qrr+pPf/qTwsPD9eqrr57y2GHDhlVJYQDOrdjIMDkddhWV+hTlKvtXQ1Gpf0K72Miwcs4GAAAAUN0qNAa+YcOG+u6771S7dm01bNjw5BczDG3fvr1KCzzXGAOPi9XxMfDr93iUXIsx8AAAAMC5UtEcWqEW+B07dpT7M4ALh81m6N5OyRo3Z6OyDhcqIdql8DB/i/yBgmLFRoSpX6dkwjsAAABQQyo1Br60tFSNGzfWxo0bq6seADWofXItjenZXC3rxyq/yKvduYXKL/Lq8vqxLCEHAAAA1LBKrQMfFhamoqKi6qoFwHmgfXIttU2K1+acI/IUlio2MkxpiTG0vAMAAAA1rNKz0A8ZMkTPPfecvF5vddQD4DxgsxlqVs+tqxvVVrN6bsI7AAAAcB6oVAu8JC1fvlzz5s3TF198oVatWikqKipo/8yZM6usOAAAAAAA4FfpAB8XF6c+ffpURy0AAAAAAOAkKh3gMzIyqqMOAAAAAABwChUeA2+app577jmlp6fryiuv1OjRo3Xs2LHqrA0AAAAAAPykwgF+3Lhx+utf/6ro6GhdeumleuWVVzRkyJDqrA0AAAAAAPykwgF+2rRpevPNN/X555/ro48+0uzZs/Xuu+/KNM3qrA8AAAAAAKgSAT47O1s33nhj4H23bt1kGIb27NlTLYUBAAAAAICfVTjAe71ehYeHB20LCwtTaWlplRcFAAAAAACCVXgWesuy1L9/f7lcrsC2oqIiDR48OGgteNaBBwAAAACg6lU4wN97771ltt19991VWgwAAAAAAChfhQM8678DAAAAAFBzKjwGHgAAAAAA1BwCPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAAIQAAjwAAAAAACGAAA8AAAAAQAggwAMAAAAAEAII8AAAAAAAhAACPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAAIQAAjwAAAAAACGAAA8AAAAAQAggwAMAAAAAEAII8AAAAAAAhAACPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAAIQAAjwAAAAAACGAAA8AAAAAQAggwAMAAAAAEAII8AAAAAAAhAACPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAAIQAAjwAAAAAACGAAA8AAAAAQAggwAMAAAAAEAII8AAAAAAAhAACPAAAAAAAIYAADwAAAABACCDAAwAAAAAQAgjwAAAAAACEAAI8AAAAAAAhgAAPAAAAAEAIIMADAAAAABACCPAAAAAAAIQAAjwAAAAAACGAAA8AAAAAQAggwAMAAAAAEAII8AAAAAAAhAACPAAAAAAAIYAADwAAAABACAiZAD9u3Dh16tRJkZGRiouLK/eY7Oxs9ezZU5GRkUpMTNSoUaPk9XrPbaEAAAAAAFQDR00XUFElJSW67bbbdM011+gf//hHmf0+n089e/ZUvXr1tGTJEu3du1f9+vVTWFiYxo8fXwMVAwAAAABQdQzLsqyaLqIyMjMzNXz4cOXl5QVt//TTT/W73/1Oe/bsUd26dSVJU6ZM0SOPPKIDBw7I6XRW6Pr5+fmKjY2Vx+OR2+2u6vIBAAAAAAhS0RwaMl3oT+ebb75Rq1atAuFdknr06KH8/HytX7/+pOcVFxcrPz8/6AUAAAAAwPnmggnw+/btCwrvkgLv9+3bd9LzJkyYoNjY2MArKSmpWusEAAAAAOBM1GiAHz16tAzDOOVr06ZN1VrDo48+Ko/HE3jt2rWrWu8HAAAAAMCZqNFJ7B566CH179//lMc0atSoQteqV6+eli1bFrRt//79gX0n43K55HK5KnQPAAAAAABqSo0G+ISEBCUkJFTJta655hqNGzdOOTk5SkxMlCTNnTtXbrdbLVq0qJJ7AAAAAABQU0JmGbns7GwdPnxY2dnZ8vl8Wr16tSQpNTVV0dHRuu6669SiRQvdc889ev7557Vv3z499thjGjJkCC3sAAAAAICQFzLLyPXv319vv/12me0LFixQly5dJElZWVn685//rK+++kpRUVG699579eyzz8rhqPhzCpaRAwAAAACcSxXNoSET4M8VAjwAAAAA4Fy66NaBBwAAAADgQkaABwAAAAAgBBDgAQAAAAAIAQR4AAAAAABCAAEeAAAAAIAQQIAHAAAAACAEEOABAAAAAAgBBHgAAAAAAEIAAR4AAAAAgBBAgAcAAAAAIAQQ4AEAAAAACAEEeAAAAAAAQgABHgAAAACAEECABwAAAAAgBBDgAQAAAAAIAQR4AAAAAABCAAEeAAAAAIAQQIAHAAAAACAEEOABAAAAAAgBjpouAMCFxzQtbc45Ik9hqWIjw5SWGCObzajpsgAAAICQRoAHUKVWZB3W20uytDWnQCVen5wOu1ITo3Vvp2S1T65V0+UBAAAAIYsu9ACqzIqswxo3Z6O+/9Ejd7hDl8VHyh3u0Po9Ho2bs1Ersg7XdIkAAABAyCLAA6gU07S0aV++lm4/pE378mWaVmD720uylFdYqpTakYpyOWS3GYpyOZRcK1KeY6WatiQrcDwAAACAyqELPYAKO1X3+CiXQ1tzCpQY45JhBI93NwxDCdEubckp0OacI2pWz11DnwAAAAAIXQR4ABVyvHt8XmGpEmNcCg9z6ViJVyuzc7Vxb76ua5moYq9P4WGuMudaknymJc+xEq3b7WFSOwAAAOAMEOABnNYvu8cbhqG8wlLtzi3U0RKv9ntNZS7Okt1mKDzMrnru8MC5uYUl2nnoqI4W+eSzTL25YKv+b8vBs5rUjlnuAQAAcDEiwAM4rc05R4K6x+cVlmpLzhF5TUtOu032MEMlXlOWJW3NKZDLYVN8pFO7c49p24EC+X4a926zGcovKtWKrMPanVuoMT2bVzrEM8s9AAAALlZMYgcgSHmT1HkKS1Xi9Sk8zC7LsrQ7t1Be01KEwyaHzZDDbpNhM3RpvL/lffP+Au3J+0V4NySX3VBBsU95haXa5zlW6UntmOUeAAAAFzNa4IELRFV0Kz9Z63aXpglyOuwqKvXJsqSjJV457bbAZHU+05LNMFQryiWn3absw4Xaecgf8g1Jjp/qKPaZMk2pxJBKfaZW78qt8KR25XXjl6Qol0ORTruyDhdq2pIstU2Kpzs9AAAALkgEeOACUBXdysubpK6o1Kf1ezzadbhQtaKc2us5Jne4Q6Yl2X/KyJakEp+pmHCHolwORYTZ5TlWqmOlpnymqTC7TUVef/C3GYYcNsm0LJX6LO3xFGnZ9sMVCvC/7MZ/Ima5BwAAwMWALvRAiKuKbuWnW8M9v6hUhmHJHe7QgYISyZJ8luQ1LR0r9clhM3RZfKQMSUWlPtltNjnshmyGVPzT2Hi7YcgwJBmS8dPLsqQFP+RUqBv9id34yxMeZleJ1ydPYWklv0EAAAAgNBDggRB2uuDtOVZaoXHmFWndPlRQqnuuSVbbpDg57IaOlnhV+lPLe5O6MYqLCJNlWTpQUKza0WE6VuJTideS17Rk/hT2rRPKsCwpymXX/vxibc45ctrPGhsZFujGX56iUn/Pg9jIsNN/cQAAAEAIIsADIawy3cpPpaKt25fGReqVO9vqiZtaKqV2lGpFOZVSO0oxLoeOFnuVdbhQdpuhI0Ve/7j4E8aiH18L3v+S7DZDDWtHVbjVPC0xRqmJ0TpQUCzLCn4gcfzBQZPEaKUlxpz2WgAAAEAoIsADIayqupVXpnXbZjN0S7vL9GyfVmrbIF5HirzanVuo/CKvWtaPVWJMuHym1KxejMIdNp34WMGSZFr+Se0aJ0QrPMxe4VZzm83QvZ2SFRsRpqzDhTpa7H9IcPzBQWxEmPp1SmYCOwAAAFywmMQOCGEnBu8oV9n/O1e0W/nx1u31ezyKdNqDWvOPt25fXj82qHW7fXIttU2KD5r53rQsPfzvtUqMcSnK5VDTejH6fk++Srymjl/SkJSaGK1LYsOVdbiwzHVPpX1yLY3p2TwwYd/BgmI5HXZdXj9W/VgHHgAAABc4AjwQws4keJfneOv2uDkblXW4UAnRLoWH+R8MHCgoPmnrts1mBM34vnT7oZ96BLgkSXGRTrW8xK0f9h+R17TktNtU6vPJMHTGreblPTg4kyXzAAAAgFBDF3oghFVlt/Ljrdst68cq/4Ru8ZfXj9WYns0r1LpdXlf8+CinmtVzKy4iTD7TkmkZKvKalbpueZ+7WT23rm5UW83quQnvAAAAuCgY1i9ng7rI5efnKzY2Vh6PR243a0kjNJS3DnyTxOgz6lZumtYZt26bpqXhM1Zr/R6PkmtFBvUIME1TWw4cVXKtSI3p2ZzgDQAAAPykojmUAP8LBHiEqrMJ3lXp+Lr0nmOl5XbFP9NWdwAAAOBCRYA/QwR44OxVZY8AAAAA4EJX0RzKJHYAqhwTzQEAAABVjwAPoFr8coZ6AAAAAGeHWegBAAAAAAgBBHgAAAAAAEIAAR4AAAAAgBBAgAcAAAAAIAQQ4AEAAAAACAEEeAAAAAAAQgABHgAAAACAEECABwAAAAAgBBDgAQAAAAAIAY6aLgAATsY0LW3OOSJPYaliI8OUlhgjm82o6bIAAACAGkGAB3BeWpF1WG8vydLWnAKVeH1yOuxKTYzWvZ2S1T65Vk2XBwAAAJxzdKEHcN5ZkXVY4+Zs1Pc/euQOd+iy+Ei5wx1av8ejcXM2akXW4ZouEQAAADjnCPAAziumaentJVnKKyxVSu1IRbkcstsMRbkcSq4VKc+xUk1bkiXTtGq6VAAAAOCcIsADOK9szjmirTkFSoxxyTCCx7sbhqGEaJe2/P/27jwoqjNrA/jTKM0i3RB2iLIoirjgKEYEx63CiMskmqRwHVdGo6LRaIzLxKA4RmMwTspJGY0OWGqN0ZpMYlzGQhQ1iIoIRgmiMCKCEMYNQaJs5/sjxf1soREM0tz4/Kqosu89773n9ltHOH2XLirFlaISE2VIRERERGQabOCJqEUpLqtAeWUVLM1b1bne0rwVyiurUFxW0cyZERERERGZFht4ImpRbK3NoW3dCg8rqupc/7Dilwfa2VqbN3NmRERERESmxQaeiFqUTs46+Djb4H+ljyBieJ+7iOB/pY/Q0dkGnZx1JsqQiIiIiMg02MATUYtiZqbB5GBP2FqZ4/qdMjx4VImqasGDR5W4fqcMtlbmmBTsye+DJyIiIqIXDht4ImpxAjzt8ZcRfujqbov7DyuRd7cM9x9Wopu7Lf4ywo/fA09EREREL6TWpk6AiKguAZ726NnuJVwpKkFxWQVsrc3RyVnHM+9ERERE9MJiA09ELZaZmQadXfWmToOIiIiIqEXgJfREREREREREKsAGnoiIiIiIiEgF2MATERERERERqQAbeCIiIiIiIiIVYANPREREREREpAJs4ImIiIiIiIhUgA08ERERERERkQqwgSciIiIiIiJSATbwRERERERERCrABp6IiIiIiIhIBdjAExEREREREakAG3giIiIiIiIiFWADT0RERERERKQCrU2dQEsjIgCA+/fvmzgTIiIiIiIiehHU9J81/agxbOCfUFJSAgBo166diTMhIiIiIiKiF0lJSQlsbW2NrtfI01r8F0x1dTVu3rwJnU4HjUZj6nQa7f79+2jXrh1u3LgBvV5v6nSokTh/6sb5Uz/Oobpx/tSPc6hunD914/yZloigpKQE7u7uMDMzfqc7z8A/wczMDG3btjV1Gr+aXq9n4akY50/dOH/qxzlUN86f+nEO1Y3zp26cP9Op78x7DT7EjoiIiIiIiEgF2MATERERERERqQAb+N8YCwsLREZGwsLCwtSp0DPg/Kkb50/9OIfqxvlTP86hunH+1I3zpw58iB0RERERERGRCvAMPBEREREREZEKsIEnIiIiIiIiUgE28EREREREREQqwAaeiIiIiIiISAXYwKvM6tWrERwcDGtra9jZ2dUZk5ubixEjRsDa2hrOzs5YtGgRKisr693unTt3MGHCBOj1etjZ2SE8PBylpaXP4QjocQkJCdBoNHX+JCcnGx03aNCgWvEzZ85sxsyphpeXV625WLt2bb1jHj58iIiICDg4OMDGxgZvvfUWfvrpp2bKmGrk5OQgPDwc3t7esLKyQocOHRAZGYny8vJ6x7H+TOvzzz+Hl5cXLC0tERgYiLNnz9Ybv3fvXnTu3BmWlpbo3r07Dh482EyZ0pPWrFmDV155BTqdDs7Ozhg1ahQyMzPrHRMbG1ur3iwtLZspY3rcihUras1F586d6x3D+ms56vp7RaPRICIios541l7LxQZeZcrLyxEWFoZZs2bVub6qqgojRoxAeXk5Tp06he3btyM2NhYffvhhvdudMGEC0tPTERcXh/379+PEiROYMWPG8zgEekxwcDAKCgoMfv785z/D29sbvXv3rnfs9OnTDcatW7eumbKmJ0VFRRnMxdy5c+uNf/fdd/Hdd99h7969OH78OG7evIk333yzmbKlGpcvX0Z1dTU2b96M9PR0bNiwAV988QWWLVv21LGsP9P46quvsGDBAkRGRuL8+fPo0aMHQkNDUVRUVGf8qVOnMG7cOISHhyM1NRWjRo3CqFGjcOnSpWbOnADg+PHjiIiIwOnTpxEXF4eKigoMGTIEDx48qHecXq83qLfr1683U8b0pK5duxrMxffff280lvXXsiQnJxvMXVxcHAAgLCzM6BjWXgslpEoxMTFia2tba/nBgwfFzMxMCgsLlWWbNm0SvV4vjx49qnNbP/74owCQ5ORkZdmhQ4dEo9FIfn5+k+dOxpWXl4uTk5NERUXVGzdw4ECZN29e8yRF9fL09JQNGzY0OP7evXtibm4ue/fuVZZlZGQIAElKSnoOGVJjrFu3Try9veuNYf2ZTp8+fSQiIkJ5XVVVJe7u7rJmzZo640ePHi0jRowwWBYYGChvv/32c82TGqaoqEgAyPHjx43GGPt7h5pfZGSk9OjRo8HxrL+Wbd68edKhQweprq6ucz1rr+XiGfjfmKSkJHTv3h0uLi7KstDQUNy/fx/p6elGx9jZ2Rmc8Q0JCYGZmRnOnDnz3HOm/7dv3z7cvn0bU6dOfWrsrl274OjoiG7dumHp0qUoKytrhgypLmvXroWDgwN69uyJTz75pN5bVlJSUlBRUYGQkBBlWefOneHh4YGkpKTmSJfqUVxcDHt7+6fGsf6aX3l5OVJSUgxqx8zMDCEhIUZrJykpySAe+OV3ImutZSguLgaAp9ZcaWkpPD090a5dO4wcOdLo3zP0/F29ehXu7u5o3749JkyYgNzcXKOxrL+Wq7y8HDt37sS0adOg0WiMxrH2WqbWpk6AmlZhYaFB8w5AeV1YWGh0jLOzs8Gy1q1bw97e3ugYej62bduG0NBQtG3btt648ePHw9PTE+7u7vjhhx+wePFiZGZm4uuvv26mTKnGO++8g169esHe3h6nTp3C0qVLUVBQgE8//bTO+MLCQmi12lrPsHBxcWG9mVhWVhY2btyI6OjoeuNYf6Zx69YtVFVV1fk77vLly3WOMfY7kbVmetXV1Zg/fz769euHbt26GY3z9fXFP/7xD/j7+6O4uBjR0dEIDg5Genr6U39XUtMKDAxEbGwsfH19UVBQgJUrV6J///64dOkSdDpdrXjWX8v1zTff4N69e5gyZYrRGNZey8UGvgVYsmQJPv7443pjMjIynvqgEGo5nmVO8/LycPjwYezZs+ep23/8+QTdu3eHm5sbXn31VWRnZ6NDhw7PnjgBaNz8LViwQFnm7+8PrVaLt99+G2vWrIGFhcXzTpXq8Cz1l5+fj6FDhyIsLAzTp0+vdyzrj+jXi4iIwKVLl+q9hxoAgoKCEBQUpLwODg6Gn58fNm/ejFWrVj3vNOkxw4YNU/7t7++PwMBAeHp6Ys+ePQgPDzdhZtRY27Ztw7Bhw+Du7m40hrXXcrGBbwEWLlxY7ydgANC+ffsGbcvV1bXWE3lrnm7t6upqdMyTDwCqrKzEnTt3jI6h+j3LnMbExMDBwQGvv/56o/cXGBgI4JcziGwgfr1fU5OBgYGorKxETk4OfH19a613dXVFeXk57t27Z3AW/qeffmK9NZHGzt/NmzcxePBgBAcHY8uWLY3eH+uveTg6OqJVq1a1vrGhvtpxdXVtVDw1jzlz5igPzG3smTxzc3P07NkTWVlZzyk7aig7Ozt06tTJ6Fyw/lqm69ev48iRI42+aoy113KwgW8BnJyc4OTk1CTbCgoKwurVq1FUVKRcFh8XFwe9Xo8uXboYHXPv3j2kpKQgICAAAHD06FFUV1crf5hS4zR2TkUEMTExmDRpEszNzRu9v7S0NACAm5tbo8dSbb+mJtPS0mBmZlbrtpQaAQEBMDc3R3x8PN566y0AQGZmJnJzcw0+6aZn15j5y8/Px+DBgxEQEICYmBiYmTX+0TCsv+ah1WoREBCA+Ph4jBo1CsAvl2HHx8djzpw5dY4JCgpCfHw85s+fryyLi4tjrZmIiGDu3Ln497//jYSEBHh7ezd6G1VVVbh48SKGDx/+HDKkxigtLUV2djYmTpxY53rWX8sUExMDZ2dnjBgxolHjWHstiKmfokeNc/36dUlNTZWVK1eKjY2NpKamSmpqqpSUlIiISGVlpXTr1k2GDBkiaWlp8p///EecnJxk6dKlyjbOnDkjvr6+kpeXpywbOnSo9OzZU86cOSPff/+9dOzYUcaNG9fsx/eiOnLkiACQjIyMWuvy8vLE19dXzpw5IyIiWVlZEhUVJefOnZNr167Jt99+K+3bt5cBAwY0d9ovvFOnTsmGDRskLS1NsrOzZefOneLk5CSTJk1SYp6cPxGRmTNnioeHhxw9elTOnTsnQUFBEhQUZIpDeKHl5eWJj4+PvPrqq5KXlycFBQXKz+MxrL+WY/fu3WJhYSGxsbHy448/yowZM8TOzk755pWJEyfKkiVLlPjExERp3bq1REdHS0ZGhkRGRoq5ublcvHjRVIfwQps1a5bY2tpKQkKCQb2VlZUpMU/O4cqVK+Xw4cOSnZ0tKSkpMnbsWLG0tJT09HRTHMILbeHChZKQkCDXrl2TxMRECQkJEUdHRykqKhIR1p8aVFVViYeHhyxevLjWOtaeerCBV5nJkycLgFo/x44dU2JycnJk2LBhYmVlJY6OjrJw4UKpqKhQ1h87dkwAyLVr15Rlt2/flnHjxomNjY3o9XqZOnWq8qEAPX/jxo2T4ODgOtddu3bNYI5zc3NlwIABYm9vLxYWFuLj4yOLFi2S4uLiZsyYRERSUlIkMDBQbG1txdLSUvz8/OSjjz6Shw8fKjFPzp+IyM8//yyzZ8+Wl156SaytreWNN94waBqpecTExNT5/+njn22z/lqejRs3ioeHh2i1WunTp4+cPn1aWTdw4ECZPHmyQfyePXukU6dOotVqpWvXrnLgwIFmzphqGKu3mJgYJebJOZw/f74y3y4uLjJ8+HA5f/588ydPMmbMGHFzcxOtVisvv/yyjBkzRrKyspT1rL+W7/DhwwJAMjMza61j7amHRkSkGU/4ExEREREREdEz4PfAExEREREREakAG3giIiIiIiIiFWADT0RERERERKQCbOCJiIiIiIiIVIANPBEREREREZEKsIEnIiIiIiIiUgE28EREREREREQqwAaeiIiIiIiISAXYwBMRETUhLy8v/O1vf2uy7U2ZMgWjRo1qsu0BQEJCAjQaDe7du9ek2yUiIqLniw08ERFRHaZMmQKNRgONRgOtVgsfHx9ERUWhsrKy3nHJycmYMWNGk+Xx2WefITY2tsm21xipqakICwuDi4sLLC0t0bFjR0yfPh1XrlwxST4tVUM/tNmyZQsGDRoEvV7PD1CIiOiZsIEnIiIyYujQoSgoKMDVq1excOFCrFixAp988kmdseXl5QAAJycnWFtbN1kOtra2sLOza7LtNdT+/fvRt29fPHr0CLt27UJGRgZ27twJW1tbLF++vNnz+S0oKyvD0KFDsWzZMlOnQkREKsUGnoiIyAgLCwu4urrC09MTs2bNQkhICPbt2wfg/y9tX716Ndzd3eHr6wug9tlYjUaDrVu34o033oC1tTU6duyobKNGeno6/vjHP0Kv10On06F///7Izs422E+NQYMGYc6cOZgzZw5sbW3h6OiI5cuXQ0SUmB07dqB3797Q6XRwdXXF+PHjUVRU1ODjLisrw9SpUzF8+HDs27cPISEh8Pb2RmBgIKKjo7F582Yl9vjx4+jTpw8sLCzg5uaGJUuWGFylMGjQIMydOxfz58/HSy+9BBcXF3z55Zd48OABpk6dCp1OBx8fHxw6dEgZU3OJ/4EDB+Dv7w9LS0v07dsXly5dMsjzX//6F7p27QoLCwt4eXlh/fr1Buu9vLzw0UcfYdq0adDpdPDw8MCWLVsMYm7cuIHRo0fDzs4O9vb2GDlyJHJycpT1Ne9/dHQ03Nzc4ODggIiICFRUVCjHd/36dbz77rvKFRvGzJ8/H0uWLEHfvn0bPBdERESPYwNPRETUQFZWVsqZdgCIj49HZmYm4uLisH//fqPjVq5cidGjR+OHH37A8OHDMWHCBNy5cwcAkJ+fjwEDBsDCwgJHjx5FSkoKpk2bVu+l+tu3b0fr1q1x9uxZfPbZZ/j000+xdetWZX1FRQVWrVqFCxcu4JtvvkFOTg6mTJnS4OM8fPgwbt26hffff7/O9TVXBOTn52P48OF45ZVXcOHCBWzatAnbtm3DX//611r5Ojo64uzZs5g7dy5mzZqFsLAwBAcH4/z58xgyZAgmTpyIsrIyg3GLFi3C+vXrkZycDCcnJ7z22mtK45ySkoLRo0dj7NixuHjxIlasWIHly5fXut1g/fr16N27N1JTUzF79mzMmjULmZmZyvsUGhoKnU6HkydPIjExETY2Nhg6dKjBPB87dgzZ2dk4duwYtm/fjtjYWGU/X3/9Ndq2bYuoqCgUFBSgoKCgwe8zERFRowkRERHVMnnyZBk5cqSIiFRXV0tcXJxYWFjIe++9p6x3cXGRR48eGYzz9PSUDRs2KK8ByAcffKC8Li0tFQBy6NAhERFZunSpeHt7S3l5+VPzEBEZOHCg+Pn5SXV1tbJs8eLF4ufnZ/RYkpOTBYCUlJSIiMixY8cEgNy9e7fO+I8//lgAyJ07d4xuU0Rk2bJl4uvra5DL559/LjY2NlJVVaXk+/vf/15ZX1lZKW3atJGJEycqywoKCgSAJCUlGeS3e/duJeb27dtiZWUlX331lYiIjB8/Xv7whz8Y5LNo0SLp0qWL8trT01P+9Kc/Ka+rq6vF2dlZNm3aJCIiO3bsqJX/o0ePxMrKSg4fPiwiv7z/np6eUllZqcSEhYXJmDFjDPbz+Jw/zdPefyIiImN4Bp6IiMiI/fv3w8bGBpaWlhg2bBjGjBmDFStWKOu7d+8OrVb71O34+/sr/27Tpg30er1ySXtaWhr69+8Pc3PzBufVt29fg0u1g4KCcPXqVVRVVQH45ez0a6+9Bg8PD+h0OgwcOBAAkJub26Dty2OX49cnIyMDQUFBBrn069cPpaWlyMvLU5Y9fvytWrWCg4MDunfvrixzcXEBgFqX+QcFBSn/tre3h6+vLzIyMpR99+vXzyC+X79+Bu/Dk/vWaDRwdXVV9nPhwgVkZWVBp9PBxsYGNjY2sLe3x8OHD5VbGACga9euaNWqlfLazc2tUbckEBERNZXWpk6AiIiopRo8eDA2bdoErVYLd3d3tG5t+GuzTZs2DdrOk825RqNBdXU1gF8uy29KDx48QGhoKEJDQ7Fr1y44OTkhNzcXoaGhBpeF16dTp04AgMuXLxs00c+qruN/fFnNBwA170lTqu+9Ly0tRUBAAHbt2lVrnJOTU4O2QURE1Jx4Bp6IiMiINm3awMfHBx4eHrWa96bi7++PkydPKvd2N8SZM2cMXp8+fRodO3ZEq1atcPnyZdy+fRtr165F//790blz50afLR4yZAgcHR2xbt26OtfXfP2Zn58fkpKSDM7YJyYmQqfToW3bto3aZ11Onz6t/Pvu3bu4cuUK/Pz8lH0nJiYaxCcmJqJTp04GZ8vr06tXL1y9ehXOzs7w8fEx+LG1tW1wnlqt1uCsPxER0fPCBp6IiMiE5syZg/v372Ps2LE4d+4crl69ih07digPWqtLbm4uFixYgMzMTPzzn//Exo0bMW/ePACAh4cHtFotNm7ciP/+97/Yt28fVq1a1aic2rRpg61bt+LAgQN4/fXXceTIEeTk5ODcuXN4//33MXPmTADA7NmzcePGDcydOxeXL1/Gt99+i8jISCxYsABmZr/+T4yoqCjEx8fj0qVLmDJlChwdHZUn8i9cuBDx8fFYtWoVrly5gu3bt+Pvf/873nvvvQZvf8KECXB0dMTIkSNx8uRJXLt2DQkJCXjnnXcMbgF4Gi8vL5w4cQL5+fm4deuW0bjCwkKkpaUhKysLAHDx4kWkpaUpDzQkIiJ6GjbwREREJuTg4ICjR4+itLQUAwcOREBAAL788st674mfNGkSfv75Z/Tp0wcRERGYN28eZsyYAeCXS79jY2Oxd+9edOnSBWvXrkV0dHSj8xo5ciROnToFc3NzjB8/Hp07d8a4ceNQXFysPGX+5ZdfxsGDB3H27Fn06NEDM2fORHh4OD744INnezOesHbtWsybNw8BAQEoLCzEd999pzxzoFevXtizZw92796Nbt264cMPP0RUVFSjnrZvbW2NEydOwMPDA2+++Sb8/PwQHh6Ohw8fQq/XN3g7UVFRyMnJQYcOHQwuvX/SF198gZ49e2L69OkAgAEDBqBnz561vlaQiIjIGI009Ek1REREZHKDBg3C7373O4Pvmv+tSUhIwODBg3H37l3lK+uIiIiIZ+CJiIiIiIiIVIENPBEREREREZEK8BJ6IiIiIiIiIhXgGXgiIiIiIiIiFWADT0RERERERKQCbOCJiIiIiIiIVIANPBEREREREZEKsIEnIiIiIiIiUgE28EREREREREQqwAaeiIiIiIiISAXYwBMRERERERGpwP8BfsiUEKZjxXMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree with data after PCA**"
      ],
      "metadata": {
        "id": "UBov1FLx6bB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load data\n",
        "data_path=\"/content/combined_Helicobacter_pylori.data\"\n",
        "\n",
        "data = pd.read_csv(data_path, header=None, delimiter=',')\n",
        "\n",
        "# Split features and target\n",
        "X = data.iloc[:, :-1].values  # Features (nucleotide sequences)\n",
        "y = data.iloc[:, -1].values   # Target labels (genotype)\n",
        "\n",
        "# Split the Dataset into Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_standardized = scaler.fit_transform(X_train)\n",
        "X_test_standardized = scaler.transform(X_test)\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=15)\n",
        "X_train_pca = pca.fit_transform(X_train_standardized)\n",
        "X_test_pca = pca.transform(X_test_standardized)\n",
        "\n",
        "# Encode the target variable\n",
        "labelencoder = LabelEncoder()\n",
        "y_train_encoded = labelencoder.fit_transform(y_train)\n",
        "y_test_encoded = labelencoder.transform(y_test)\n",
        "\n",
        "# Initialize the DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Train the classifier with PCA output\n",
        "classifier.fit(X_train_pca, y_train_encoded)\n",
        "\n",
        "# Predict the labels of the PCA-transformed test set\n",
        "y_predicted = classifier.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test_encoded, y_predicted))\n",
        "print(classification_report(y_test_encoded, y_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py7WX5K769Kn",
        "outputId": "9aaadb74-13f6-400d-871a-1150bb7caf87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 0 0 0]\n",
            " [1 5 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89         4\n",
            "           1       1.00      0.83      0.91         6\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.95      0.96      0.95        15\n",
            "weighted avg       0.95      0.93      0.93        15\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Some Conclusions about Normalization and PCA**"
      ],
      "metadata": {
        "id": "4QD3Qpot-irj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After a series of experiments conducted on the dataset, it was determined that normalization was not necessary for our analysis. Given that the attributes take one of four discrete values, these features do not exhibit a meaningful continuous scale that would benefit from normalization techniques, which are typically used to standardize ranges in data with variable distances and scales. Additionally, the application of Principal Component Analysis (PCA) was found to be unnecessary in this context. Due to the relatively small size of our dataset, PCA did not yield any performance improvements. However, in scenarios involving much larger datasets, possibly encompassing thousands of entries, the use of PCA could potentially be beneficial. In such cases, PCA can help in reducing dimensionality, thus speeding up processing times and possibly enhancing model performance by focusing on the most relevant features."
      ],
      "metadata": {
        "id": "x7yMEia6-q0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Normalization**"
      ],
      "metadata": {
        "id": "uMXQYqk6LgFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Load the data\n",
        "file_path = \"/content/combined_Helicobacter_pylori.data\"\n",
        "data = pd.read_csv(file_path, header=None)\n",
        "\n",
        "# Separate features and target\n",
        "X = data.iloc[:, :-1]  # all columns except the last\n",
        "y = data.iloc[:, -1]   # the last column\n",
        "\n",
        "# Initialize scalers\n",
        "min_max_scaler = MinMaxScaler()\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "# Apply MinMax normalization\n",
        "X_min_max = min_max_scaler.fit_transform(X)\n",
        "min_max_normalized_data = pd.DataFrame(X_min_max, columns=X.columns)\n",
        "min_max_normalized_data['Target'] = y\n",
        "min_max_normalized_data.to_csv('/content/min_max_normalized_data.csv', index=False)\n",
        "\n",
        "# Apply Standard normalization (Z-score)\n",
        "X_standard = standard_scaler.fit_transform(X)\n",
        "standard_normalized_data = pd.DataFrame(X_standard, columns=X.columns)\n",
        "standard_normalized_data['Target'] = y\n",
        "standard_normalized_data.to_csv('/content/standard_normalized_data.csv', index=False)\n",
        "\n",
        "# Decimal Scaling\n",
        "def decimal_scaling(data):\n",
        "    max_abs = np.abs(data).max()\n",
        "    factor = 10 ** np.ceil(np.log10(max_abs + 1e-9))\n",
        "    return data / factor\n",
        "\n",
        "X_decimal_scaled = decimal_scaling(X)\n",
        "decimal_scaled_data = pd.DataFrame(X_decimal_scaled, columns=X.columns)\n",
        "decimal_scaled_data['Target'] = y\n",
        "decimal_scaled_data.to_csv('/content/decimal_scaled_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "1cWsi-EIK0v1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}